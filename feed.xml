<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-02-07T21:22:13+00:00</updated><id>/</id><title type="html">Joseph Hamilton - Solution Oriented Data Scientist</title><subtitle>A website by and for Joseph Hamilton. A place to explore projects and pursuits, to chase curiosities and catch dreams.
</subtitle><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><entry><title type="html">Project McNulty Begins</title><link href="/project/mcnulty/2018/02/06/Project-McNulty-Begins/" rel="alternate" type="text/html" title="Project McNulty Begins" /><published>2018-02-06T00:00:00+00:00</published><updated>2018-02-06T00:00:00+00:00</updated><id>/project/mcnulty/2018/02/06/Project-McNulty-Begins</id><content type="html" xml:base="/project/mcnulty/2018/02/06/Project-McNulty-Begins/">&lt;p&gt;Project McNulty begins.&lt;/p&gt;

&lt;p&gt;OK.  Once bitten, twice shy.&lt;/p&gt;

&lt;p&gt;They &lt;strong&gt;TOLD&lt;/strong&gt; us last time to submit two ideas for Project Two and to be able to
pivot to the second one if things didn’t work out with the first.  I am not sure
anyone actually did so.  I cannot even remember what my second idea was.  I know
I gave it very little consideration.&lt;/p&gt;

&lt;p&gt;Now, to be fair, it was hard to assess things.  First of all, half of that project
was scraping.  We couldn’t even look at data until we had it.  Furthermore, a lot
of us wouldn’t have really known how.  But we WERE getting a sense of the lack of
correlation at the MVP stage.  I imagine several of us could have, should have
hopped at that point.  Again though… we didn’t know.  For example, I spent
time scraping &lt;em&gt;more&lt;/em&gt; data.  I had fun.  It as a worthwhile experience.  I proved
in MongoDB.  But only towards the end did I look at the learning curves which
made it really, really clear more data wasn’t going to help me at all.&lt;/p&gt;

&lt;p&gt;So… THIS time I’m treating both ideas seriously and have already pulled down
the initial datasets for both.  As much as is feasible I’m going to do a quick,
hasty deep dive to look for “signal”.  Things like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Are there worthy correlations between features and target?&lt;/li&gt;
  &lt;li&gt;Is the classification going to be skewed due to imbalanced categoricals?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I plan to have things like that addressed very shortly.  I may be able to add
features later.  But I don’t want to get stuck chasing ghosts this time.&lt;/p&gt;

&lt;p&gt;David called this “fail fast”.  We need to be able to determine quickly when
to “fail” and move on rather than falling trap to a sunk cost fallacy.&lt;/p&gt;

&lt;p&gt;Let’s see how this goes…&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project McNulty begins.</summary></entry><entry><title type="html">Bootcamp - Investigation One</title><link href="/metis/2018/02/06/Investigation-One/" rel="alternate" type="text/html" title="Bootcamp - Investigation One" /><published>2018-02-06T00:00:00+00:00</published><updated>2018-02-06T00:00:00+00:00</updated><id>/metis/2018/02/06/Investigation-One</id><content type="html" xml:base="/metis/2018/02/06/Investigation-One/">&lt;p&gt;I gave the presentation for the first of two Investigations today!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/slides/docker/&quot; target=&quot;_blank&quot;&gt;Here it is.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The investigations have started.&lt;/p&gt;

&lt;p&gt;No… it’s not the Spanish Inquisition.&lt;/p&gt;

&lt;p&gt;Every student in the cohort has to give two presentations on “Investigations”
at some time during the Bootcamp.  I believe it was the first or second day
when the instructors pointed us to a schedule on Google Docs.  We had to sign
up for two timeslots.&lt;/p&gt;

&lt;p&gt;I dutifully ignored this.&lt;/p&gt;

&lt;p&gt;I mean how could I even think about researching some random topic in the midst
of all the pressure related to the projects!?!  and the Challenges!!&lt;/p&gt;

&lt;p&gt;Somewhere in the past couple of weeks, I caught a whiff or a conversation between
Alice some of the students.  I didn’t quite catch what prompted the discussion.
But it seemed to be something along the lines of someone commenting about all
the things to do and the struggle of the pressure relative to scheduling and
prioritizing.&lt;/p&gt;

&lt;p&gt;Alice provided this order of prioritization:2018-01-24-Project-Luther-Begins.md&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Projects&lt;/li&gt;
  &lt;li&gt;Blog&lt;/li&gt;
  &lt;li&gt;Challenges&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now… that doesn’t appear to mean just jettison stuff… No, we got a brief
(and supposedly one-time) bit of chastisement from David this morning on
submitting things on time as expected.  And none of that could have pertained
to the Project since we all do that stuff (MVPs, standups, Presentations, etc.).
The only exception so far has been Amy who was out sick on the day for Presentations
on Project Two and she gave her presentation belatedly after I presented my
Investigation.&lt;/p&gt;

&lt;p&gt;So… you can run, but you can’t hide.  David pestered me last week so I finally signed
up for Investigations.  I chose one early date and one late date since I plan on
one “easy” and one “hard” topic.  OK.  Truth be told, you wait to be almost the
last one to sign up, you no longer have choice of slots.&lt;/p&gt;

&lt;p&gt;Docker was on the list of suggested topics, so I jumped on it given my love for
things related to virtualization and my experience playing with containers of
various OSs.&lt;/p&gt;

&lt;p&gt;I stayed with reveal.js and like before I tried to explore some new functionality
of reveal.js while doing so.  I used the “cube” transition which, I discovered,
locks you into that for the full presentation - no per-slide overrides.  It seems
to have to with how both sides of the transition have to work with the format.&lt;/p&gt;

&lt;p&gt;But the real fun was incorporating “shellinabox” which permitted me to include
a terminal &lt;strong&gt;within&lt;/strong&gt; the presentation for the purposes of a live demo.  This
worked well.  It was “cool” to have the terminal be a part of the cube transition.
What did not work as well was what would seem to be simpler - just incorporating
websites in iframes in a slide.  I mean… that’s a precursor or dependency of
the functionality for shellinabox!!  But I just could not get it to work.  I 
did manage to use something so I bounced from the presentation to website and
back rather seamlessly… by using some hack for debugging that’s been left in
reveal.js as an undocumented feature.  So I did keep in the spirit of not
exiting the presentation.  But still… sheesh!&lt;/p&gt;

&lt;p&gt;Another “fun” aspect was that earlier in the day Alice walked the group through installing postgresql
in EC2 instances on AWS.  From there we were supposed to be able to pull the
data into local Jupyter notebooks.  We had all sorts of problems because of
some odd postgresql issues.  It was funny to use as a demo an example of firing
up a local Docker with postgresql and have it all work immediately.  Of course, this
was a bit of apples to oranges since the work to get that to work with Juptyer
would be very similar.&lt;/p&gt;

&lt;p&gt;This was the “easy” investigation.  I have high hopes for the next one to be
much more interesting.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">I gave the presentation for the first of two Investigations today!</summary></entry><entry><title type="html">Illness Strikes</title><link href="/metis/2018/02/06/Illness-Strikes/" rel="alternate" type="text/html" title="Illness Strikes" /><published>2018-02-06T00:00:00+00:00</published><updated>2018-02-06T00:00:00+00:00</updated><id>/metis/2018/02/06/Illness-Strikes</id><content type="html" xml:base="/metis/2018/02/06/Illness-Strikes/">&lt;p&gt;My family has been hit by the flu.&lt;/p&gt;

&lt;p&gt;You can prepare all you want for all kinds of mishaps.  But you cannot
prevent them.&lt;/p&gt;

&lt;p&gt;I’ll not be the first in the cohort to be absent due to illness.  Amy won
that prize.  But I will have to take a couple days absence this week.&lt;/p&gt;

&lt;p&gt;Fortunately (so far) it’s not me.  Oh, I’ve been nursing my own bugs.
But my stuff has been annoying sinusitis.  What did the doctor call it?
I think she said it was “sub-acute sinusitis”.  The “sub” part is easy
to diagnose.  If it’s not “sub-acute” you don’t wait several weeks to
go to the doctor.  In any case, I did go to the doctor after the first
week of the Bootcamp.  That may have been incredibly fortuitous because
I got the flu shot while I was there.  I hope that helps protect me.&lt;/p&gt;

&lt;p&gt;My son showed significant symptoms Sunday morning and my daughter
succumbed late yesterday afternoon..&lt;/p&gt;

&lt;p&gt;Oh yeah… I’d better call that attendance line…  Come to think of it,
I wonder if my wife called it yesterday…&lt;/p&gt;

&lt;p&gt;I alerted the Metis instructors that this week might be dicey.  My wife
shifted some responsibilities off to coworkers and took Monday and Tuesday
off.  Alice suggested later this week might be feasible for me to stay
home and work remotely.&lt;/p&gt;

&lt;p&gt;There may be no “good” time to deck out of this intensive bootcamp.
But this may be better than other times.  The third project is just beginning.
I give my first investigation this afternoon.&lt;/p&gt;

&lt;p&gt;I just hope I don’t the flu myself.  That would be… bad… very bad.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">My family has been hit by the flu.</summary></entry><entry><title type="html">Project Luther - Presentation and Wrapup</title><link href="/project/luther/2018/02/02/Project-Luther-Presentation-and-Wrapup/" rel="alternate" type="text/html" title="Project Luther - Presentation and Wrapup" /><published>2018-02-02T00:00:00+00:00</published><updated>2018-02-02T00:00:00+00:00</updated><id>/project/luther/2018/02/02/Project-Luther-Presentation-and-Wrapup</id><content type="html" xml:base="/project/luther/2018/02/02/Project-Luther-Presentation-and-Wrapup/">&lt;p&gt;Project Luther Presentations were today!&lt;/p&gt;

&lt;p&gt;Project Luther is nearing completion.&lt;/p&gt;

&lt;p&gt;Everyone presented this morning.  (well… almost everyone… Amy has been out sick the last couple days).&lt;/p&gt;

&lt;p&gt;I feel into an odd trap with this project.  This was a two-part project.  The first parts was web-scraping.
This part can be time intensive and indeed rather frustrating as you deal with odd issues.  But nonetheless,
it’s fairly straightfoward.  You set out with a rather specifc task and target: get THAT data.  The second
part was far more murky.  Sure, it may be that linear regression could be viewed as systematic.  You do
X, Y and Z, possibly iteratively.  But this would ignore the primary difficulties.&lt;/p&gt;

&lt;p&gt;This part, the linear regression part, is more akin to the “Science” in “Data Science” than “Data”.  You
are essentially running an experiment.  The pattern you seek may simply not exist.  You may end up with
a null result.&lt;/p&gt;

&lt;p&gt;You do need to do a good job ensuring you’ve done your due diligence in attacking the problem.  And you
need to develop whatever insight you can, even if the main goal of a predictive model isn’t fulfilled.&lt;/p&gt;

&lt;p&gt;As I worked on the presentation, I would occasionally need a chart.  That might require rerunning a
function or model.  And a presentation slide may need an explanation of an issue.  To better explain
something, is even more investigation needed?  Can you tweak the model this way or that to learn more
or see anything differently?  In short, you could end up right back in a never-ended cycle chasing
modeling.&lt;/p&gt;

&lt;p&gt;From just the point-of-view of the presentation itself, I chose to continue with reveal.js.  I did indeed
further develop my skills there.  Since it essentially IS a website, this lets me learn more about CSS
as well.  I may eventually add in some custom javascript for my own desired effects.  So using reveal.js
for the presentations is preparing me for the upcoming focus on things like D3.  For example, on several
slides I employed “flex” for placement on the slides.&lt;/p&gt;

&lt;p&gt;I also made use of the “export to PDF” aspect of reveal (rumor was the instructors wanted a PDF).
  It does work, after a fashion.  But it did
something hilarious with the panoramic background.  I’m not entirely sure, but it seems it used the
vertical offset - as if the PDF pages were constantly going “down” rather than “right”.  Tis a minor
thing.  A more serious thing is that I used the heirarchical organization of reveal to slip in
extra, appendix-like, material into the slide presentation.  I didn’t actually use these extra hidden
slides.  Indeed, they were hidden so well I don’t think anyone realized I had the extras.  But they
aren’t hidden when exporting to PDF.  They’re unfolded and put back into the sequence.  Interesting.&lt;/p&gt;

&lt;p&gt;The feedback I was given on the presentation chided me for focusing too much on WHAT I did and not WHY.
That is, I’d lost view of the Storytelling aspect of the presentation and project.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Luther Presentations were today!</summary></entry><entry><title type="html">Project Luther - Analysis</title><link href="/project/luther/2018/02/01/Project-Luther-Analysis/" rel="alternate" type="text/html" title="Project Luther - Analysis" /><published>2018-02-01T00:00:00+00:00</published><updated>2018-02-01T00:00:00+00:00</updated><id>/project/luther/2018/02/01/Project-Luther-Analysis</id><content type="html" xml:base="/project/luther/2018/02/01/Project-Luther-Analysis/">&lt;p&gt;Project Luther provides plenty of opportunity for playing around with data.&lt;/p&gt;

&lt;p&gt;We have covered quite a lot of material related to linear regression techniques
and issues over the last few days.  Some of this felt like decent review,
especially since I have done this both on HackerRank and via the MOOC series
I was pursuing.  Other parts were completely new to me.  I now have a much
better idea how to describe Ridge and Lasso Regression.  And there was a lot
of depth regarding a variety of issues.&lt;/p&gt;

&lt;p&gt;One key takeaway, for example, was to be very wary of using R^2 for any sort
of model comparison.  Maybe use Adjusted R^2 since it is better for comparing
modeling with different sets of features.  But the idea is that R^2 will always
increase slightly with added features even if those features have more
predictive power.  Even better still is just to focus on
root-means-squared-error.&lt;/p&gt;

&lt;p&gt;I have been digging into sklearn.  There’s a lot of power here.  So much so
that it’s easy to jump into using these module, classes and functions with
precious little degree of understanding.&lt;/p&gt;

&lt;p&gt;There’s something to be said to coding stuff up from scratch to develop
understanding.&lt;/p&gt;

&lt;p&gt;I ended up doing that yesterday.  I was trying to repeat some of what we’d
discussed with my current data and modeling.  I wanted to &lt;strong&gt;SEE&lt;/strong&gt; the model’s
behavior.  Is it “High Bias”, “High Variance”?  It seemed easy enough to
extrapolate from our work in train-test splits or cross-validation to create
what I needed.  I still feel so clumsy with Matplotlib.  But I did it.&lt;/p&gt;

&lt;p&gt;And then David (one of the instructors) came by and said “Oh, you recreated
sklearn’s learning curve.  Sheesh.  Truth be known, if I’d know that was there,
I likely would have just used it!!&lt;/p&gt;

&lt;p&gt;Anyway, here’s what I did:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_test_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;''' Create a set of train/test samples.
        The goal here is random sets of a certain size.
        There is no intention of these sets being non-overlapping.
        Size is same for both test and train unless the requested
        size is more than half of the N provided.
        Input:
            N    the size of the data
            k    the number or samples desired
            size the size of the samples desired
        Output:
            List of pairs of list of indices
    '''&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;learning_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; Create a plot to visualize the learning of the model.
    Inputs:
        est    the estimator
        X      the features
        y      the target
        points the number of tests
        rep    the number of repetitions at each test size
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_ind&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_test_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives a “clumsy” picture like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/slides/Luther/Chart_x01.png&quot; alt=&quot;Learning Curve &quot; /&gt;&lt;/p&gt;

&lt;p&gt;So I then ran off and found the quasi-official sample function to use with the
sklearn learning-curve fucntion.  That ends up looking something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/slides/Luther/Chart_02.png&quot; alt=&quot;Learning Curve &quot; /&gt;&lt;/p&gt;

&lt;p&gt;If it wasn’t humbling enough to switch to the “nice” functions and charts, the
really sobering thing here is what both of these charts showed.  After I’d
had all that fun creating a robust scraping regimen to get tens of thousands of
records, these charts underscored rather powerfully that for some instances,
more data doesn’t really help.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Luther provides plenty of opportunity for playing around with data.</summary></entry><entry><title type="html">Metis - Open House</title><link href="/metis/2018/01/31/Metis-OpenHouse/" rel="alternate" type="text/html" title="Metis - Open House" /><published>2018-01-31T00:00:00+00:00</published><updated>2018-01-31T00:00:00+00:00</updated><id>/metis/2018/01/31/Metis-OpenHouse</id><content type="html" xml:base="/metis/2018/01/31/Metis-OpenHouse/">&lt;p&gt;Tonight, I stayed after the Bootcamp to join the Metis Open House.&lt;/p&gt;

&lt;p&gt;It’s a strange experience to participate in another Open House on the other side of
the Bootcamp process.&lt;/p&gt;

&lt;p&gt;And it’s &lt;strong&gt;IMMENSELY&lt;/strong&gt; surreal to hear Alice, one of the Instructors, describe how
much fun it is for the instructors to push us through high-pressure, fast projects.&lt;/p&gt;

&lt;p&gt;Chuckle…&lt;/p&gt;

&lt;p&gt;But… there’s free food.  And it was good food.  Giordano’s pizza!!&lt;/p&gt;

&lt;p&gt;And it seemed good to stay here and focus on the current project.&lt;/p&gt;

&lt;p&gt;But… this second project has ended up a tad strange.  The instructors really guided
us to segment the work on this project.  So, for me, this meant today was Analysis.
Scraping was supposed to be done.  I actually had set my spiders such that they could
just run in the background.  So while I did analyisis today, the spiders increased my
record count from 50k to 60k.  Tomorrow the focus is on the Presentation.&lt;/p&gt;

&lt;p&gt;For some projects, the analysis could go on forever.  But there’s not much you can
do with bad data.  If there is no signal to capture, you get the pleasure of doing
nothing other than proving that point.  So, to a degree today’s been a bit of winding
down.  I’m focusing on methodology and at least creating good Jupyter Notebooks that
can be useful later.&lt;/p&gt;

&lt;p&gt;About half the cohort stayed for the Open House.  Tiffany even brought her husband along.&lt;/p&gt;

&lt;p&gt;We were informed there would be a couple past alumni presenting their projects.  Then
Nathan told us today that was a miscommunication.  Finally, it seems he found someone
to present, at least here in Chicago.  This was actually the major draw for me.  I
don’t really need to hear the pitch all over again.  But getting more ideas for the
Passon Project will certainly be helpful.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Tonight, I stayed after the Bootcamp to join the Metis Open House.</summary></entry><entry><title type="html">Project Luther Continues</title><link href="/project/luther/2018/01/30/Project-Luther-Continues/" rel="alternate" type="text/html" title="Project Luther Continues" /><published>2018-01-30T00:00:00+00:00</published><updated>2018-01-30T00:00:00+00:00</updated><id>/project/luther/2018/01/30/Project-Luther-Continues</id><content type="html" xml:base="/project/luther/2018/01/30/Project-Luther-Continues/">&lt;p&gt;Project Luther continues.&lt;/p&gt;

&lt;p&gt;We present on Friday.  However, the Instructors have issued the stricture that we must have our analysis complete
by end-of-day Wednesday.  Now… I may take a bit of issue with what “end-of-day” means.  But they’ve specified
Thursday is to be solely for development of presentations.&lt;/p&gt;

&lt;p&gt;For me, this means that Tuesday was/is for &lt;strong&gt;more&lt;/strong&gt; data scraping.  And Wednesday is primarily going to be devoted
to analysis.  Or to put it another way, I cannot do a good job on the presentation if I’m still fighting with the
analysis.  And I cannot do justice to the analysis, if I’m still scrambling over scraping.&lt;/p&gt;

&lt;p&gt;There’s simply not enough time to do all of what we want on these projects.  I had hoped to incorporate some
basic Unit Testing and CI support.  That’s out.  But I &lt;strong&gt;did&lt;/strong&gt; implement the pipeline to MongoDB as a backend.
My fears may have been unwarranted.  But I was leery of issues of concurrent scrapes dumping to a single
text file.  It was likely not really an issue.  I had though the concurrency setting was set to “1”.  But that
was what I had seen as I reviewed the project from last year.  In any case, I’m happy to have incorporated
MongoDB.&lt;/p&gt;

&lt;p&gt;I did implement a scraping approach that could end up pulling all the property tax data from Will County…
if it’s left to run long enough.  It’s still a bit slow for some odd reason.  Maybe, I can tweak it a bit…
who knows.&lt;/p&gt;

&lt;p&gt;But I’ve already shifted to analysis.  The pair-plots seemed to show me that there may yet be some pattern or
signal to capture but it’s being swamped by outliers.  So I started doing some box-plots and histograms to get
a sense for things… And oh boy!  I have outliers.&lt;/p&gt;

&lt;p&gt;I still have work to do to incorporate a good number of my features.  And I may be able to create some
more features based on aggregated data (assuming I can get reasonably close to a complete scrape).  But even
with the initial set of records, it’s clear there are things I could do.  I may end up jettisoning some records
to get rid of outliers.   Or I may switch those features to logarithms.  I’ll have to experiment.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="MongoDB" /><summary type="html">Project Luther continues.</summary></entry><entry><title type="html">Bootcamp - Transit Woes</title><link href="/metis/2018/01/30/Bootcamp-Transit-Woes/" rel="alternate" type="text/html" title="Bootcamp - Transit Woes" /><published>2018-01-30T00:00:00+00:00</published><updated>2018-01-30T00:00:00+00:00</updated><id>/metis/2018/01/30/Bootcamp-Transit-Woes</id><content type="html" xml:base="/metis/2018/01/30/Bootcamp-Transit-Woes/">&lt;p&gt;I’m stuck on a train!!  :cry:&lt;/p&gt;

&lt;p&gt;We have folk who take Uber.  We have those who navigate the CTA, bus and rail.  Few drive on a
regular basis.&lt;/p&gt;

&lt;p&gt;I’ve driven a couple of times so far.  It may make more sense for me to take the train.  But there are times,
I need to do things in the afternoon or evening where I need the car.  From a raw time perspectice, so far,
it seems driving gets me there slightly earlier.  Rumor has it there might be some places to park for free.
I just use the parking lot next to the Metis facility.  They have an “early bird” special if you get in before
a certain time.  But… the first time I drove, something really weird happened.  When I tried to exit, I ended
up in a slow line of cars.  The car in front of me seemed to be stuck for some odd reason.  And I kept hearing
noises like they were talking to someone over the intercom.  I’d never seen anything like this in that garage.
I had always parked there when coming to Metis for weekend or evening stints.  Strange.  It was like being
behind someone counting out pennies at a toll booth.  My turn came… and I had the pleasure of discovering
the cause for the backup - their scanner wouldn’t work… at all.  So it became my chance to push the intercom
and begin the goofy discussion trying to explain to the person on the other end what was wrong.  They tried
to take my information (info from the silly ticket).  They determined my rate and attempted to set that
manually on their end.  Even that didn’t work.  Eventually they just raised the bar remotely and let me out.
I guess I should be thankful that part of the system still worked.&lt;/p&gt;

&lt;p&gt;The next day?  Back to normal.  Weird.&lt;/p&gt;

&lt;p&gt;Well, I’ve experienced slight delays on the Metra.  But tonight is my first opportunity to be trapped on
a broken train.  Oh what fun.  It could be worse, of course.  If I were stuck in gridlock traffic on the
Eisenhower, for example, it wouldn’t be practical to whip out the laptop and fire off a few blog posts.
But I must say it’s adding insult to injury to watch the later trains zoom by on the alternate track.&lt;/p&gt;

&lt;p&gt;At the moment, Metra has another train behind us pushing us.  Not sure what the outcome of that will be.
It seems the plan is huff and puff and crawl to the nearest station.  And then we get off and get on
another train?&lt;/p&gt;

&lt;p&gt;Yup… that was the ticket.&lt;/p&gt;

&lt;p&gt;I’m back home now.  We were pushed to the station where we all had to get off and cross to the other
side where another train was waiting for us.  It seems that one was one of the later trains that had been
commandeered to assist us.  I wondered when I’d eventually have to ride the Metra standing.  That ended 
being today.  While balancing in the aisle on a bouncing, lurching train, my son called me.  I had to
hang up on him quickly because it was a tad difficult to manage it all.&lt;/p&gt;

&lt;p&gt;Whew.  Well… I hope that doesn’t happen again anytime soon.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">I’m stuck on a train!! :cry:</summary></entry><entry><title type="html">Project Luther - MVP</title><link href="/project/luther/2018/01/29/Project-Luther-MVP/" rel="alternate" type="text/html" title="Project Luther - MVP" /><published>2018-01-29T00:00:00+00:00</published><updated>2018-01-29T00:00:00+00:00</updated><id>/project/luther/2018/01/29/Project-Luther-MVP</id><content type="html" xml:base="/project/luther/2018/01/29/Project-Luther-MVP/">&lt;p&gt;Project Luther passes MVP.&lt;/p&gt;

&lt;p&gt;I gave the MVP for Luther earlier today.&lt;/p&gt;

&lt;p&gt;I was actually quite bewildered with what to do given the sense that there was nothing really to show.&lt;/p&gt;

&lt;p&gt;This is a bit of a trap.  There are so many interesting little traps we can fall into.
There’s the problem of perfectionism… where we may want to keep improving or tweaking or correcting
or whatever well beyond a reasonable timeframe.  There are lots of pitfalls with regards to misunderstanding
the data or not fully appreciating the algorithms or tools being used.&lt;/p&gt;

&lt;p&gt;Then, there is the entire issue of what IS an MVP.&lt;/p&gt;

&lt;p&gt;The curriculum today actually included a few pointers and references on this topic.  It seems as much as
is possible the idea is to have progressed fairly far through the goals of the project with a small sample
of the data.  This irks me somewhat because for a large class of projects, once you’re able to do something
with a small bit of data, there’s not much to do related to scaling.  In short, if you can crunch a few
records, you’re already almost completely done.&lt;/p&gt;

&lt;p&gt;In my case, the goal was to have completed data scraping and have done some regression.  I had reached that
point.  I hadn’t done much beyond that.&lt;/p&gt;

&lt;p&gt;Since some of my peers had indeed developed slide presentations, I followed suit.  I chose to develop a
presentation in reveal.js from the beginning.  This made it straightforward to put it on the blog immediately,
since quite literally it was being served from a local instance of the blog.&lt;/p&gt;

&lt;p&gt;I was able to switch immediately to the underlying Jupyter notebook to show the bit of regression I’d done…&lt;/p&gt;

&lt;p&gt;which seemed to show almost no coorelation at all between my target and the various features.&lt;/p&gt;

&lt;p&gt;The other aspect of this round of presenting MVPs was the time allotted.  It was to be about two minutes.&lt;/p&gt;

&lt;p&gt;For this particular project, the final presentations need to similarly terse.  We get a whopping five minutes.&lt;/p&gt;

&lt;p&gt;For MVP, I scraped about 5,000 records.  After some cleaning and such, I had a bit more than 1,500 records.
The greatest feature-target correlation was about 0.1.&lt;/p&gt;

&lt;p&gt;Nonetheless, it was easy to chart out the “next steps”: more data and more analysis.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Luther passes MVP.</summary></entry><entry><title type="html">Bootcamp - Week Two Down</title><link href="/metis/2018/01/27/Bootcamp-Week-Two-Down/" rel="alternate" type="text/html" title="Bootcamp - Week Two Down" /><published>2018-01-27T00:00:00+00:00</published><updated>2018-01-27T00:00:00+00:00</updated><id>/metis/2018/01/27/Bootcamp-Week-Two-Down</id><content type="html" xml:base="/metis/2018/01/27/Bootcamp-Week-Two-Down/">&lt;p&gt;I have completed Week Two of the Metis Bootcamp!&lt;/p&gt;

&lt;p&gt;I vaguely remember the concept of sleep.  It’s like an old friend I’ll have to visit again once the Bootcamp concludes.&lt;/p&gt;

&lt;p&gt;It’s one thing to look at a curriculum and see Web Scraping and say, “Oh yeah… I know how to do that”.  It’s a
completely different thing to rush through a project where you first have to dream up &lt;strong&gt;WHAT&lt;/strong&gt; to explore, then &lt;strong&gt;HOW&lt;/strong&gt;
to find the related data on the Web and finally to pull together some mechanism to do so in short order.&lt;/p&gt;

&lt;p&gt;In essence, there’s a significant difference between any project you may have done in the past which spanned several
weeks and one where you’re under terrible pressure to do it all very quickly.&lt;/p&gt;

&lt;p&gt;Project One is pretty much the only project where you are even barely spoon fed.  The instructors don’t tell you exactly
where to go and what to do (well… that’s not entirely true… they do… but only you’ve after done it… which is
hilarious).  But the requirements for Project One fairly strongly push you in a certain direction and you end up working
from a small set of sources for your data.  None of that is true for the rest of the Bootcamp.  You are given structure
only in the sense of what methods need to be employed.  But dreaming up what to study is on you.  This is entirely
on purpose since this is a rather valuable facet of being a Data Scientist.  Can you determine what to study in order
to drive towards a desired goal?  Or do you have to be spoon fed what to do?&lt;/p&gt;

&lt;p&gt;But knowing this doesn’t make it any easier.  It’s rather difficult.&lt;/p&gt;

&lt;p&gt;I had a lot of fun this past week with Pair Programming.  I think part of it is that we’re all getting to know one
another better.  So there’s less of the typical sense of guardedness or competition or fear of looking foolish.
Another piece of the puzzle may be that we’re all so overwhelmed or exhausted that if anyone can drive things towards
the goal, we’re happy no matter who drives.&lt;/p&gt;

&lt;p&gt;Project Two is actually entirely solo.  But it does fall in line with my earlier assessment that the projects
overall trend from group to solo.  So, Project Two is solo… but… we’ve all been paired with a “buddy”.  The
instructors waited till folk had chosen their focus of study in order to pair people up based on topic.  I have no
idea how well this functions for most cohorts, but for our cohort it sort of magically worked out because we 
really did end up with many people chasing similar topics.  We’re supposed to be an aid or a cheerleader to our
buddy.  We’ve been given explicit instruction that whenever we hit a roadblock we go to our buddy first before
hitting up the instructors.&lt;/p&gt;

&lt;p&gt;This helps.  But I’ve actually been learning lots of little things from everyone.  I &lt;em&gt;did&lt;/em&gt; follow my buddy (Nate)
in dumping data to a text file first before anything else.  Easy to see.  Easy to pull into pandas in a Jupyter
notebook for more experimentation.  Sure I want a more robust mechanism.  But, do that later.  I have also been
intrigued by those who chose topics I discarded because I couldn’t quickly determine how to look up data to scrape.  One
trick appears to be just to tack on “database” after the topic in a typical web search.&lt;/p&gt;

&lt;p&gt;In week two, we actually got a decent amount of instruction related to how to do Project Two before or during the
execution of the project.  For so much of this, there still remains a lot more we have to figure out beyond that.
Furthermore, the various challenges we face depends a lot of what we’re actually tackling.&lt;/p&gt;

&lt;p&gt;Also, in week two we started with workshops and meetings with Career Services.  For many of us, our first contacts
with Metis involved the Program Manager, Nathan.  When you start doing “things” with Metis, you deal with Nathan
for pretty much any particular event.  And, as you might imagine, the &lt;strong&gt;Program&lt;/strong&gt; Manager is our interface to
all sorts of logistics, such as when anyone gets stuck in the elevator or the heating in the building doesn’t quite 
seem to be working.  But I must say even if Ashley never gave a lecture or met with me personally, it only takes
couple of weeks of being in the same work space to realize that woman works hard.  Though things may change in the
future Nathan and Ashley have a sort of open office arrangement.  And due to the arrangement of rooms, their desks
are in between the lecture room and the restrooms.  So we can hear Ashley hard at work.  And we can easily imagine
that’ll be us on the other end of that phone in a few months.&lt;/p&gt;

&lt;p&gt;A lot of what Career Services is providing is stuff I’ve heard before since this is sort of my third round through
these sorts of agencies.  Nonetheless, it’s good to get it tailored a bit towards this specific industry.&lt;/p&gt;

&lt;p&gt;Oh… another thought I’ll toss in here before I wrap up this week’s summary.  Our TA Ibrahim was in on Friday.
We had some interesting discussions with him.  A lot of us really don’t yet have a good feel for this industry.
Ask me the major telecom companies and I can rattle them off.  I cannot yet do that for Data Science.  We queried
Ibrahim for stuff like that.  But even more interesting was when someone pressed him to contrast his experience
in his Masters Porgram with the Bootcamp.  See… Ibrahim is a relatively recent grad of the Metis Bootcamp himself.
He snuck the Bootcamp in between the years of his Masters program in, I believe, Statistics.  Ibrahim stated he
wanted to do the Bootcamp to help him build his portfolio because he couldn’t easily use his projects at school
to do the same (due to restrictions, NDAs, etc.).  I found this fascinating given how hard it is to assess
the benefit of having a portfolio.&lt;/p&gt;

&lt;p&gt;I realize one can never really be sure of everything… you know… Plato’s cave and all that.  But, if I needed
little tidbits to help me feel better about my reasons for jumping into the Bootcamp (as expensive as it is), I have several:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ibrahim stepping “down” from a Masters in Statistics into the Metis Bootcamp to build up his portfolio.&lt;/li&gt;
  &lt;li&gt;Adam, who as a Data Science Recruiter decided he didn’t just want to help Data Science folk get a job.  He wanted to
go and become a Data Scientist.&lt;/li&gt;
  &lt;li&gt;Dean, whose wife is a recent graduate of the Metis Bootcamp (and who deleted her Project One work so he couldn’t copy it…
chuckle…).  I mean, as a couple, they decided after paying for one of them to pay for the other.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">I have completed Week Two of the Metis Bootcamp!</summary></entry></feed>