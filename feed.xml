<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-03-25T21:36:22+00:00</updated><id>/</id><title type="html">Joseph Hamilton - Solution Oriented Data Scientist</title><subtitle>A website by and for Joseph Hamilton. A place to explore projects and pursuits, to chase curiosities and catch dreams.
</subtitle><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><entry><title type="html">Bootcamp - Blogging about Projects</title><link href="/metis/2018/03/25/Blogging-Projects/" rel="alternate" type="text/html" title="Bootcamp - Blogging about Projects" /><published>2018-03-25T00:00:00+00:00</published><updated>2018-03-25T00:00:00+00:00</updated><id>/metis/2018/03/25/Blogging-Projects</id><content type="html" xml:base="/metis/2018/03/25/Blogging-Projects/">&lt;p&gt;It’s a challenge to keep up with the blogging!&lt;/p&gt;

&lt;p&gt;We had an interesting and rather lively feedback session Friday.  We’d been talking about
doing one for a bit.  So David finally hosted it.&lt;/p&gt;

&lt;p&gt;One of the more interesting things to come out of it was a consistent call that Dask
should be introduced into the curriculum immediately following Pandas.  This may have been
about the only thing where the cohort at least had no dissenting views.  Most of the feedback
was diverse in the sense that not everyone agreed.&lt;/p&gt;

&lt;p&gt;But Dask?  Not everyone had delved into it.  But many had dabbled a bit.  And Alex did give
a good Investigation presentation on the topic.  Many of us had run into issues throughout
the bootcamp which this could have addressed.  This main problem is what to do when your
local machine runs out of memory?  For most of this there have only been two choices:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reboot after the crash and try again with a smaller data set.&lt;/li&gt;
  &lt;li&gt;Move it to the cloud somehow.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But moving to the cloud isn’t trivial.  Do you try to create a single EC2 instance with
a ton of RAM?  Or try out something on EMR with the work spread out?  Both of these weren’t
something we could have done early on in the bootcamp.  Sometimes you can restructure your
work so you process a large file one line at a time.  But that’s what Dask does for you!!&lt;/p&gt;

&lt;p&gt;I rolled some swap space.  I’ve now got lots more virtual memory.  So my machine doesn’t
lock up or crash any longer.  But things get slow once I’m chewing through swap.&lt;/p&gt;

&lt;p&gt;Dask, however, would have a been a natural and straightforward solution many of us could
have incorporated rather easily even back in Project One.  And Dask would have provided us
an immediate benefit on a local machine well before taking advantage of its full power on
a cluster.&lt;/p&gt;

&lt;p&gt;One of the more lively topics of discussion related to the Challenges.  I dutifully completed
all the required challenges.  I am actually looking forward to doing some of the optional ones
later… after the conclusion of the bootcamp.  But it seemed pretty clear nobody did the
optional ones.  Indeed, many didn’t actually complete the required ones.  They just turned
them incomplete.  Oh well…&lt;/p&gt;

&lt;p&gt;Another thing that became optional halfway through the bootcamp was blogging about the projects.
This one seems a bit odd.  I mean… that’s pretty much the entire point of the bootcamp - to
develop a portfolio of projects which you display via your blog and/or GitHub.  In this case,
the issue is timing.  You can go back and work on your blogs later.  This seems to be what
a lot of folk do.&lt;/p&gt;

&lt;p&gt;Well… I’ve started to blog to keep a few notes along the way for Project Five.  But I’d not
yet even really started the blogging for Projects Three and Four… tsk… tsk!  So in between
some work on Project Five this afternoon I stopped and fluffed out the structure for the remaining
projects.  Soon I’ll put up the presentations for Project Four.  There’s something I want to go
back and finish for the final presentation of Project Three.  So I may wait on that.  We’ll see…&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="Blog" /><category term="Dask" /><summary type="html">It’s a challenge to keep up with the blogging!</summary></entry><entry><title type="html">Trouble with Clusters</title><link href="/project/kojak/2018/03/22/Trouble-with-Clusters/" rel="alternate" type="text/html" title="Trouble with Clusters" /><published>2018-03-22T00:00:00+00:00</published><updated>2018-03-22T00:00:00+00:00</updated><id>/project/kojak/2018/03/22/Trouble-with-Clusters</id><content type="html" xml:base="/project/kojak/2018/03/22/Trouble-with-Clusters/">&lt;p&gt;I’m starting to take advantage of clusters on the Cloud for parallel processing power.&lt;/p&gt;

&lt;p&gt;The problem isn’t that there’s not a way to do this.  The problem is that there are
so many ways of doing this.  This is a very dynamic field.&lt;/p&gt;

&lt;p&gt;At a very high level, there’s Amazon and Google.  I’ve tabled Google for the moment.  But I’ll get
back over there eventually.&lt;/p&gt;

&lt;p&gt;But within Amazon, there are many options.&lt;/p&gt;

&lt;p&gt;For general Hadoop, there’s EMR.  But even there we have many options.  I explored the use of
MRjob for a previous project.  I never made it very far.  This was nice in the way it automatically
set up the cluster and permitted a very structured way to slip in Python code at the various stages
of the overall Map-Combine-Reduce flow.  I used it for some small experiments with TF-IDF.  But
I didn’t have to time then to iron out all the issues with setting up instances and containers
appropriately for needs for that project.&lt;/p&gt;

&lt;p&gt;But it seems now that Spark is the way to do Python with a Hadoop structure.  MRJob does actually now work
with Spark.  So I may return to explore that.&lt;/p&gt;

&lt;p&gt;Then we have Zeppelin notebooks which work rather nicely with Spark, either directly in Scala or
via pyspark.  So now we have several layers of how to do things in notebooks.  There’s Jupyter
Notebooks, Jupyter Notebooks in Jupyter Labs and Zeppelin notebooks.&lt;/p&gt;

&lt;p&gt;I tripped over myself yesterday firing up an EMR cluster to play with Zeppelin some more.  This
was a reminder than anything manual will involve problems sooner or later.  So, yesterday I backed
off and slammed in a local install of Spark with Zeppelin in a Docker container.  In all honesty,
I should probably be doing initial prototyping and experimentation locally anyway.  So it was
rather important to get it setup.  But… let’s now try to wrap things up so I can get an EMR
cluster going with Zeppelin/Spark support with as little manual support needed.&lt;/p&gt;

&lt;p&gt;So… my goals:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Do everything related to setting up the cluster via the AWS CLI.&lt;/li&gt;
  &lt;li&gt;End up with the command to set up the tunnel and the URL for Zeppelin.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using the AWS CLI, let’s create a bucket and upload a bootstrap shell script.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws s3 mb s3://aws-&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;AWSID&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-boots&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where {AWSID} is the AWS account ID.  S3 bucket names need to be unique.  This ought to be unique.&lt;/p&gt;

&lt;p&gt;Now, let’s create our bootstrap script.  I’ll call it &lt;code class=&quot;highlighter-rouge&quot;&gt;zep_boots.sh&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; ~/anaconda.sh

bash ~/anaconda.sh &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/anaconda

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\nexport PATH=$HOME/anaconda/bin:$PATH'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.bashrc &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.bashrc

conda install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; seaborn pandas requests

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Upload it to the bucket…&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ aws s3 cp zep_boots.sh s3://aws-${AWSID}-boots/

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I had been cloning an existing cluster.  From the AWS website, I took advantage of the “AWS CLI Export”
function to get a CLI sequence to create the cluster.  I saved it to a file and then added to the end
of this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	--bootstrap-actions Path=s3://elasticmapreduce/bootstrap-actions/run-if,Args=[&quot;instance.isMaster=true&quot;,&quot;s3://aws-${AWSID}-boots/zep_boots.sh&quot;]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Because…  that’s what &lt;a href=&quot;https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-bootstrap.html&quot;&gt;AWS says it should be&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After &lt;strong&gt;many&lt;/strong&gt; attempts and troubleshooting, here’s what you really have to do:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	--bootstrap-actions Path=s3://aws-${AWSID}-boots/zep_boots.sh

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then rather than using the broken run-if script, just incorporate the logic into your code.  I found a good example
to copy on &lt;a href=&quot;https://forums.aws.amazon.com/thread.jspa?threadID=222418&quot;&gt;the forums&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here’s a new version of &lt;code class=&quot;highlighter-rouge&quot;&gt;zep_boots.sh&lt;/code&gt; which includes setup for Graphframes.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#! /bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Determine if we are running on the master node.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 0 - running on master&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 1 - running on a task or core node&lt;/span&gt;
check_if_master&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    python - &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;__SCRIPT__&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;'
import sys
import json
 
instance_file = &quot;/mnt/var/lib/info/instance.json&quot;
is_master = False
try:
    with open(instance_file) as f:
        props = json.load(f)
 
    is_master = props.get('isMaster', False)
except IOError as ex:
    pass # file will not exist when testing on a non-emr machine
 
if is_master:
    sys.exit(0)
else:
    sys.exit(1)
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;__SCRIPT__
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

check_if_master &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;0

&lt;span class=&quot;c&quot;&gt;# Install Conda and desired modules&lt;/span&gt;

wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; ~/anaconda.sh

bash ~/anaconda.sh &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/anaconda

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\nexport PATH=$HOME/anaconda/bin:$PATH'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.bashrc &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.bashrc

conda install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; seaborn pandas requests

&lt;span class=&quot;c&quot;&gt;# Install Graphframes&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# (gonna need sudo calls here...)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Note... this is sooo kludgey&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;mkdir &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /var/lib/zeppelin/local-repo/2ANGGHHMQ
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /var/lib/zeppelin/local-repo/2ANGGHHMQ

&lt;span class=&quot;c&quot;&gt;# Need some dependencies&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;wget http://central.maven.org/maven2/com/typesafe/scala-logging/scala-logging-api_2.11/2.1.2/scala-logging-api_2.11-2.1.2.jar
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;wget http://central.maven.org/maven2/com/typesafe/scala-logging/scala-logging-slf4j_2.11/2.1.2/scala-logging-slf4j_2.11-2.1.2.jar
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;wget http://central.maven.org/maven2/org/slf4j/slf4j-api/1.7.7/slf4j-api-1.7.7.jar


&lt;span class=&quot;c&quot;&gt;# Now get graphframes&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;wget http://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.5.0-spark2.1-s_2.11/graphframes-0.5.0-spark2.1-s_2.11.jar

&lt;span class=&quot;c&quot;&gt;# Finally, prepare for pyspark access of graphframes&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;mkdir &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /usr/lib/zeppelin/interpreter/lib/python
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /usr/lib/zeppelin/interpreter/lib/python
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;jar xf /var/lib/zeppelin/local-repo/2ANGGHHMQ/graphframes-0.5.0-spark2.1-s_2.11.jar graphframes



&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This still requires going into the Interpreters in Zeppelin and changing &lt;code class=&quot;highlighter-rouge&quot;&gt;zeppelin.pyspark.python&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;/home/hadoop/anaconda/bin/python&lt;/code&gt;.  The goofy thing here is the bootstrap script is run &lt;strong&gt;before&lt;/strong&gt; the applications are loaded.  We could get away with creating directories and putting files in (as root… which is good because it prevents the “normal” things removing these files).  But the thing to do to switch to anaconda’s python would require changing a file (interpreter.json).  Hard to do if it’s not there.  And putting it in there may cause the application installation to fail.&lt;/p&gt;

&lt;p&gt;The way AWS EMR has set this up for Zeppelin seems to be… problematic and has caused a number of folk some grief when it comes to loading up additional modules and packages.&lt;/p&gt;

&lt;p&gt;But what about getting the URL for Zeppelin?  Didn’t I want to be able to ignore the AWS website entirely?&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bash create_cluster.sh
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;ClusterId&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;j-38FI39ISFYGTV&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws emr describe-cluster &lt;span class=&quot;nt&quot;&gt;--cluster-id&lt;/span&gt; j-38FI39ISFYGTV | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;State
&lt;span class=&quot;c&quot;&gt;# Wait a bit...  keep checking...&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws emr describe-cluster &lt;span class=&quot;nt&quot;&gt;--cluster-id&lt;/span&gt; j-38FI39ISFYGTV | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;Dns
        &lt;span class=&quot;s2&quot;&gt;&quot;MasterPublicDnsName&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;ec2-18-218-45-180.us-east-2.compute.amazonaws.com&quot;&lt;/span&gt;,
&lt;span class=&quot;c&quot;&gt;# Now, to set up the tunnel...&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh &lt;span class=&quot;nt&quot;&gt;-ND&lt;/span&gt; 8157 hadoop@ec2-18-218-45-180.us-east-2.compute.amazonaws.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And browse to:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;http://ec2-18-218-45-180.us-east-2.compute.amazonaws.com:8890/&lt;/code&gt;&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="Kubernetes" /><category term="AWS" /><category term="EMR" /><category term="Hadoop" /><summary type="html">I’m starting to take advantage of clusters on the Cloud for parallel processing power.</summary></entry><entry><title type="html">Bootcamp - Investigations Conclude</title><link href="/metis/2018/03/21/Investigations-Conclude/" rel="alternate" type="text/html" title="Bootcamp - Investigations Conclude" /><published>2018-03-21T00:00:00+00:00</published><updated>2018-03-21T00:00:00+00:00</updated><id>/metis/2018/03/21/Investigations-Conclude</id><content type="html" xml:base="/metis/2018/03/21/Investigations-Conclude/">&lt;p&gt;We’re all done with Investigations!&lt;/p&gt;

&lt;p&gt;Alas.  No more investigations.  No more competing fancies to vie for our time.&lt;/p&gt;

&lt;p&gt;True to form, the instructors held our feet to the fire and we did indeed wrap up all our Investigations
before Lunch on Monday.&lt;/p&gt;

&lt;p&gt;And, I was still the last one to present for whatever that’s worth.&lt;/p&gt;

&lt;p&gt;This ended up being like a project presentation day because so many were presenting back-to-back.
But it was a lot more relaxed and fun because we weren’t being evaluated.&lt;/p&gt;

&lt;p&gt;Tiffany had given one on GraphX Friday.  And Michael explored Time Series.  Monday Alex did Dask. 
Amy did Spacey.  Adam did… something
I cannot quite describe in one word.  It was a method of using a CNN to apply artistic styles
to images.  And I gave a &lt;a href=&quot;/slides/reinforcement/&quot; target=&quot;_blank&quot;&gt; presentation on reinforcement learning &lt;/a&gt;
 with a focus on bots playing games.&lt;/p&gt;

&lt;p&gt;Adam and I both had sort of transitioned an idea or hope for the Passion Project into an investigation
instead.  I started hearing an odd phrase recently… “Business Applicability”.  It has become expected
that we take ideas to the instructors (David and Alice) and have them shot down for one reason or another,
often due to things like too complex, too simple, inapplicable use of modeling assumptions, etc.  But lately
there seemed to be folk incorporating the Career Advisor (Ashley) into this discussion.  I guess the
discussions were someting like “yeah… that’s cool… but… what’s the &lt;strong&gt;business applicaton&lt;/strong&gt;”.  There
are often ways to answer that question.  Sometimes there is value in the method of approach overall even
if the end goal has less direct applicability.  But… things like weird picture generation or better AI bots
for games… well… better to have fun with it as an Investgiation.&lt;/p&gt;

&lt;p&gt;The really good thing about having everyone do investigations like this is that we all get more exposure
to what’s out there.  You can grab the work another student did whenever you need it.  This saves you a bit
of time you’d have spent wandering around the web exploring the topic.&lt;/p&gt;

&lt;p&gt;For example, I could see myself using any of these investigations during Project Five:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Dask&lt;/li&gt;
  &lt;li&gt;GraphX&lt;/li&gt;
  &lt;li&gt;Spacey&lt;/li&gt;
  &lt;li&gt;Docker&lt;/li&gt;
  &lt;li&gt;Isolation Forest&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="Reinforcement_Learning" /><summary type="html">We’re all done with Investigations!</summary></entry><entry><title type="html">Project Kojak Begins</title><link href="/project/kojak/2018/03/15/Project-Kojak-Begins/" rel="alternate" type="text/html" title="Project Kojak Begins" /><published>2018-03-15T00:00:00+00:00</published><updated>2018-03-15T00:00:00+00:00</updated><id>/project/kojak/2018/03/15/Project-Kojak-Begins</id><content type="html" xml:base="/project/kojak/2018/03/15/Project-Kojak-Begins/">&lt;p&gt;We’re finally here… we’ve crossed into Passion Project territory.&lt;/p&gt;

&lt;p&gt;And… in many ways, it’s just like the previous projects.  We’ve got till Friday to post our
two project ideas on projects slack channel.  We need to try to “fail fast” and switch to the
alternative idea if the first one proves not to be viable.&lt;/p&gt;

&lt;p&gt;But there are many rather significant differences this time.  First of all, there’s next to
no guidance or restrictions.  Unlike the previous projects, there’s no focus on Supervised vs.
Unsupervised.  There’s no requirement to use SQL or NoSQL.  No goal to incorporate visualizations.
Instead, it’s all of the above in whatever way we want.&lt;/p&gt;

&lt;p&gt;Except…&lt;/p&gt;

&lt;p&gt;The instructors are very actively involved in helping us choose projects.  This is in two primary
forms.  First, they would &lt;strong&gt;like&lt;/strong&gt; to create some sort of balance across the cohort.  For Project
Four, David made the comment that he’d very rarely, if ever, seen word clouds in project presentations.
However for some odd reason, a large percentage of us included word clouds.  They were artfully done.
But as a whole cohort it was essentially overdone.  They don’t want half of us chasing the same topic,
area or toolset for Project 5.  So, they listed about a dozen general areas and suggested to us
those which might appear more to employers.&lt;/p&gt;

&lt;p&gt;Ah yes… employers.  For Project 4 we had to hold a microphone while presenting.  It was weird.
This was to prepare us because Project 5 presentations will be livestreamed.  The primary audience
for Project 5 presentations will be employers and recruiters, both present and remote.&lt;/p&gt;

&lt;p&gt;So… if feels the instructors are even more rigorous in helping us avoid “bad” projects.  Our ideas
are getting shot down quickly.  If our ideas involve circular logic, weak assumptions, untenable
goals, etc., we’re redirected accordingly.&lt;/p&gt;

&lt;p&gt;Finally, it would &lt;strong&gt;seem&lt;/strong&gt; we have more time for this final project.  But that’s all somewhat of an
illusion.  This first week is devoted to helping us &lt;strong&gt;choose&lt;/strong&gt; a project (two projects, actually -
we need a viable alternative as well).  And the last week is earmarked for presentation refinement.
Oh yes.  There absolutely &lt;strong&gt;WILL NOT&lt;/strong&gt; be any presentations given on Career Day that were actually
tossed together or wrapped up within twelve hours of the presentation.  Oh no no no.  We’ll be
presenting internally a full week ahead of time and going through &lt;em&gt;several&lt;/em&gt; iterations for refinement.&lt;/p&gt;

&lt;p&gt;That puts much more pressure on us overall.&lt;/p&gt;

&lt;p&gt;I finally selected an alternative yesterday afternoon and posted my two ideas.  I’ve been moving large
amounts of data into an AWS S3 bucket for the purpose of EDA.  So, I’ve begun.  But my focus will be
split for a few days as I prepare the final Investigation.&lt;/p&gt;

&lt;p&gt;It seems I wasn’t the only one hoping to postpone delivery/presentation of the final Investigation.
I thought I was “safe” in this since I had the last slot on the official schedule.  But that means
little when about half the cohort was trying to push this off as well.  Alice was quite lenient in
granting these postponement requests.  But it now appears there was something missed in interpretation.
The students meant postponements on the order of a week (I’d’ve preferred a month).  She probably meant
something like a day tops.  So Alice laid down the law and declared &lt;strong&gt;ALL&lt;/strong&gt; Investigation presentations
must be completed by Monday.  This is creating a traffic jam and we’ll have something like a Project
Presentation Day because so many of us will be giving these Investigations back-to-back.&lt;/p&gt;

&lt;p&gt;Her motive is clear.  She wants us focused on Project Five.  And I see why.  I’m having lots of fun
with my Investigation.  It really is now a competing focus.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">We’re finally here… we’ve crossed into Passion Project territory.</summary></entry><entry><title type="html">HackerRank Targets: RegEx and NLP</title><link href="/hackerrank/2018/03/15/NLP-on-HackerRank/" rel="alternate" type="text/html" title="HackerRank Targets: RegEx and NLP" /><published>2018-03-15T00:00:00+00:00</published><updated>2018-03-15T00:00:00+00:00</updated><id>/hackerrank/2018/03/15/NLP-on-HackerRank</id><content type="html" xml:base="/hackerrank/2018/03/15/NLP-on-HackerRank/">&lt;p&gt;I’ve identified tracks in HackerRank to coincide with Project 4.&lt;/p&gt;

&lt;p&gt;Similar to Project Three, I thought it would be useful to progress through the related material
on HackerRank.  And as before, it was indeed uScores seful.  You don’t get the whizbang toolsets to
help you.  No SciKit Learn… No Gensim… No NLTK.  Nope.  It really does help to learn things
if you are forced to fall back and essentially code things from scratch.  And, you may learn
a lot more along the way.&lt;/p&gt;

&lt;p&gt;For example, as I coded TF-IDF from scratch, I read the Wikipedia page on TF-IDF.  Nothing
previous had underscored that there really isn’t just one TF-IDF algorithm.  There are many
variations.
Scores 
So, I chose the Regular Expression (Regex) track and the Natural Language Processing (NLP) section
withing the Machine Learning track.&lt;/p&gt;

&lt;p&gt;Alas… although it was and is helpful, it was also robust enough I couldn’t finish in the
time frame of Project 4.  I plowed all through the “learning” challenge sections for RegEx.  But
the last section is full of near-real-world applications.  I just couldn’t devote the time.
And the NLP section… sheesh.  That’s really going to take some time.&lt;/p&gt;

&lt;p&gt;I’m accumulating no small amount of curiosities and goals for things to pursue after the Metis
bootcamp.&lt;/p&gt;

&lt;p&gt;For Project 5, I’m starting to use Spark which depends on Scala.  So, in the same spirit, I
should jump on the Functional Programming track on Hacker Rank.  But… it’s going to have to wait.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="Regex" /><category term="NLP" /><summary type="html">I’ve identified tracks in HackerRank to coincide with Project 4.</summary></entry><entry><title type="html">Project Fletcher Closing</title><link href="/project/fletcher/2018/03/09/Project-Fletcher-Closing/" rel="alternate" type="text/html" title="Project Fletcher Closing" /><published>2018-03-09T00:00:00+00:00</published><updated>2018-03-09T00:00:00+00:00</updated><id>/project/fletcher/2018/03/09/Project-Fletcher-Closing</id><content type="html" xml:base="/project/fletcher/2018/03/09/Project-Fletcher-Closing/">&lt;p&gt;Project Fletcher is coming to a close…&lt;/p&gt;

&lt;p&gt;I’m on the train commuting down to Project Presentation Day.&lt;/p&gt;

&lt;p&gt;And I have just been reminded of an significant risk I’ve been running - I’m incredibly dependent upon
access to the Internet to give my presentations.  It’s not just something like developing a presentation
in Google Slides or Slides.com and never downloading an offline copy.  My presentations are live.
They are run from a local web server (on the laptop).  Although I keep trying to ensure all javascript
libraries are served locally, I’m not catching everything.  In a more perfect world, I would/should
have a completely static copy in some format or another as a backup or failsafe.&lt;/p&gt;

&lt;p&gt;Things seem to work… more or less… eventually.  But it sometimes requires reloading, kicking it, waiting.
I CAN reload the presentation now on the train with no internet access.  Not quite what I’d want while
under a strict time constraint.  Next, I need to make a note to check into something else.  I’ve now got
half a dozen slides or more with iframes pulling other pages.  Somehow, for some reason, these seem to be
falling out of cache.  Sigh…&lt;/p&gt;

&lt;p&gt;The trouble with these projects is that you are SUPPOSED to stop your exploration, your analysis, etc.,
and then have time focused just on creation and refining the presentation.  But most of us keep at it.
Sometimes, you’re really close to finishing something and once you’ve got it then that opens up a floodgate
of further analysis or insight… sometimes invalidating or overtuning previous ideas or observations
you’d baked into the presentation.  It’s a very weird thing.&lt;/p&gt;

&lt;p&gt;Nonetheless, this is a one of the most key benefits of this bootcamp.  We’re learning time management
and prioritization skills relative to projects overall.  We’re being forced to turning things around in
an iterative fashion where we can present things at various stages along the way.  This is invaluable.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Fletcher is coming to a close…</summary></entry><entry><title type="html">Bootcamp - Live Programming</title><link href="/metis/2018/03/08/Bootcamp-Live-Programming/" rel="alternate" type="text/html" title="Bootcamp - Live Programming" /><published>2018-03-08T00:00:00+00:00</published><updated>2018-03-08T00:00:00+00:00</updated><id>/metis/2018/03/08/Bootcamp-Live-Programming</id><content type="html" xml:base="/metis/2018/03/08/Bootcamp-Live-Programming/">&lt;p&gt;Pair Programming has given way to Live Programming.&lt;/p&gt;

&lt;p&gt;Pair Programming is a key part of the daily routine in the Metis Data Science Bootcamp.  Almost every day begins with
approximately half-an-hour devoted to it.  About the only exception to this is any day devoted to Project
presentations.&lt;/p&gt;

&lt;p&gt;What we &lt;strong&gt;DO&lt;/strong&gt; for Pair Programming varies quite a bit.&lt;/p&gt;

&lt;p&gt;It &lt;strong&gt;FEELS&lt;/strong&gt; almost as if they set things up to catch you off guard.  We’ll go days with what are essentially
your standard programming tutorial challenges.  Little coding challenges you can find on any website you could
use to help you learn programming.  The thing here is that once you’ve seen a good number of these, they sort
of stick in your memory and you can just draw upon that to make things work.  And since you’re in a &lt;strong&gt;pair&lt;/strong&gt;,
there’s a reasonably good chance one of you can remember what to do.  Then all of a sudden, out of the blue,
we get a challenge to code one of the algorithms we use for regression or modeling entirely from scratch.&lt;/p&gt;

&lt;p&gt;Another common variant is challenges which are really just walkthroughs.  These are actually harder than they
seem because of the time constraint.  I quite often come nowhere near finishing those.&lt;/p&gt;

&lt;p&gt;Well, we’ve finally switched` to “Live Programming”.  Rarely Pair Programming has been Solo.  Sometimes they do
want to ensure you can do it on your own.  Well, Live Programming is entirely Solo… sort of.&lt;/p&gt;

&lt;p&gt;What happens is someone is picked (supposedly) at random.  I say supposedly because it seemed very coincidental
I got selected immediately after asking whether the sampling was with replacement.  Kendall, who was selected
yesterday responded with a vehement NO.  This person who was selected must go up front and hook up their laptop
to the projector.  Between that and the white board, they respond to a challenge given by the instructors.
Everyone else must work on the same challenge… solo and in silence.  The person on the hot seat, can ask
question, of course.  But nobody else can and everyone else cannot comment on the work of the one in the
hot seat, neither to criticize, correct nor congratulate.&lt;/p&gt;

&lt;p&gt;I daresay, if the last two days are anything to go on, we do much better when we’re not the one up front.
My solution when Kendall was up front was good.  My solution when I went up front was OK.  But Nate had a
better solution.  He was somewhat shy about it but Alice pushed him to go up and show off his solution.&lt;/p&gt;

&lt;p&gt;We’re all used to going up and presenting after Pair Programming.  That’s usually how Pair Programming
sessions end.  Times up and anyone who has a working solution can go up and present.  Then anyone else
who had a solution significantly different can go up and also present.  So we’re used to presenting
&lt;strong&gt;AFTER&lt;/strong&gt; coding.  It’s presenting &lt;strong&gt;WHILE&lt;/strong&gt; coding that’s the new thing.&lt;/p&gt;

&lt;p&gt;This is all supposed to work to prepare us for all kinds of coding interview experiences.  We get feedback
from the instructors afterwards.  And sometimes, the instructors change the request or objective of the
challenge on the fly while you’re in progress.  They’re much more focused on your behavior than they
are the specific techniques.  For example, I got a little guidance on legible variable names (actually
sliding constants into variables named descriptively).  But I got called out specifically and majorly
for two behavioral issues:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;I didn’t make use of the white board despite Alice suggesting I could.&lt;/li&gt;
  &lt;li&gt;I didn’t pseudo-code first.  A bit later on I started using comments in a pseudo-code like way.
But I should have started with pseudo-code first.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The feedback isn’t all negative.  Overall they were pleased with my performance.  I did talk a fair
amount during the process (though I got quiet when wrestling with something in my head - something
that should have been whiteboarded).  They liked that I tested my functions quickly and repeatedly
while developing them.&lt;/p&gt;

&lt;p&gt;Being on the hot seat adds a bit of pressure and discomfort for a lot of us.  That’s why, of course,
we’re getting the practice.  It clouds your mind a bit.  For example, yesterday Kendall chose an approach
based on strings.  I used math instead.  Many of these could be done a number of ways.  But Kendall has
a strong Math background.  So I was surprised she chose strings.  When you’re up front, you tend to get
tunnel vision.  That’s part of why we need the practice.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Pair Programming has given way to Live Programming.</summary></entry><entry><title type="html">Project Fletcher Began</title><link href="/project/fletcher/2018/03/01/Project-Fletcher-Began/" rel="alternate" type="text/html" title="Project Fletcher Began" /><published>2018-03-01T00:00:00+00:00</published><updated>2018-03-01T00:00:00+00:00</updated><id>/project/fletcher/2018/03/01/Project-Fletcher-Began</id><content type="html" xml:base="/project/fletcher/2018/03/01/Project-Fletcher-Began/">&lt;p&gt;Project Fletcher began a while ago…&lt;/p&gt;

&lt;p&gt;I guess you might say as far as blogging goes, the cat caught my tongue.&lt;/p&gt;

&lt;p&gt;I have not yet finished blogging about Project McNulty.&lt;/p&gt;

&lt;p&gt;Which is hilarious because the storytelling part about that project was that some
nefarious group imprisoned my blog.  Lo and behold if that didn’t happen in effect.&lt;/p&gt;

&lt;p&gt;I often see graduates from previous cohorts milling around the Metis campus.
It seems very worthwhile to see what they’re up to or to ask them about their
experiences.  A fair amount of the time, they’re working with Ashley.  Some times,
they’re just coming in on a regular, if infrequent, basis and they spend their
time working on some skill or another.  But one high runner for activities is
polishing up their past projects either in their blog or in their GitHub repositories.&lt;/p&gt;

&lt;p&gt;Heavens, if I’ve not created the same problem for myself.&lt;/p&gt;

&lt;p&gt;I was behind on the last project due to planned and unplanned absences.  The instructors
gave me a grace day and I presented a day after everyone else.  They were also understanding
in the sense that they didn’t expect or require me to submit or publish my material on the
same schedule as everyone else.  But I didn’t realize they weren’t going to wait for that
to grade my work.  I’m not surprised.  They make the rounds almost every day to check up
on our progress.  Between that and us pestering them, they have a good sense of what we’re
doing.  That and the presentation itself is a good metric.&lt;/p&gt;

&lt;p&gt;In any case, the trouble was that my lag on ending Project Three meant I was already bleeding
into the time where everyone else was working on Project Four.  And if that wasn’t enough
I have started my research and work leading to my next Investigation.&lt;/p&gt;

&lt;p&gt;My focus is wildly split now.  And Project Three is the only thing where there’s no real pressure.
The others have deadlines.  Nonetheless, there’s one thing I wish to do before I publish Project
Three… so it’s gonna linger for a bit…&lt;/p&gt;

&lt;p&gt;In any case, Project Four is NLP and Unsupervised Learning, both of which can be… umm… a
tad weird.  I chose two optional scopes for the project.  We each had a private meeting with
the instructors to go over these.  Yet again, I found myself with an incorrect assessment of
which would be harder.  I knew which would be more direct and in line with the lectures, etc.
But it’s not just that the other would be a bit harder… apparently it would have been much
more difficult in the time frame available.  In my scope review meeting with the instructors, I
asked about how we would measure success for this project.  The previous two projects had various
metrics.  The response was interesting…&lt;/p&gt;

&lt;p&gt;“When you have something that makes sense.”&lt;/p&gt;

&lt;p&gt;Well… a bit of experimentation with Topic Modeling, and I have a much deeper appreciation for
that statement.&lt;/p&gt;

&lt;p&gt;Another intriguing aspect of this project is that I may actually take advantage of the AWS servers.
I may not truly need such if I limit my scope.  But to scale up, it seems very likely I’ll actually
benefit.  I don’t need an EC2 instance for MongoDB.  I just dumped stuff to my local MongoDB server
I had running since Project Two.  But, I may need some extra horsepower.  We’ll have to see what I
can accomplish…&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Fletcher began a while ago…</summary></entry><entry><title type="html">Finished SQL on HackerRank</title><link href="/hackerrank/2018/02/24/Finished-SQL-on-HackerRank/" rel="alternate" type="text/html" title="Finished SQL on HackerRank" /><published>2018-02-24T00:00:00+00:00</published><updated>2018-02-24T00:00:00+00:00</updated><id>/hackerrank/2018/02/24/Finished-SQL-on-HackerRank</id><content type="html" xml:base="/hackerrank/2018/02/24/Finished-SQL-on-HackerRank/">&lt;p&gt;Yay!!  I finally finished the SQL track on HackerRank!&lt;/p&gt;

&lt;p&gt;Project Three of the Metis Bootcamp had three areas of focus:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SQL&lt;/li&gt;
  &lt;li&gt;Classification&lt;/li&gt;
  &lt;li&gt;Data Visualization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We spun up EC2 instances on AWS to serve as database servers using Postgres.  I confirmed that past the lectures I didn’t
need to stick with that for the requirements of the Project.  That is to say, I could stick with a local server.  This was
my preference and will be for the next project as well which requires the use of MongoDB.  I used MongoDB locally for Project
Two.  So I see no reason to switch to AWS for Project Four.  I DID follow along the lecture and exercise to prove in the
functionality of using the AWS instance.  But I’m not going to bother for any project until I can see a benefit of doing so.&lt;/p&gt;

&lt;p&gt;Indeed, I’ve been thinking about that.  Alice says for the most part Data Scientists aren’t simultaneously Data Engineers.
Usually, we’ll not be &lt;strong&gt;creating&lt;/strong&gt; databases.  We’ll be using them.  In that vein, we’ll be using (usually) whatever is
already out there, whatever it might be.&lt;/p&gt;

&lt;p&gt;But… when does it makes sense for us to actually use these AWS instances over our local machines?  And then, how best
should we use them?  I’m rather curious if it would make better sense for us to run Jupyter or Jupyter Labs on the same
machine running the database server… or alternatively another instance.  To start, we’re using meager, small instances
in the free tiers.  Decent laptops surpass that.  But… maybe just maybe… we could come across something we could
parallelize and then use multiple AWS instances.  Or, possibly, we’d benefit from letting something run for a long time.&lt;/p&gt;

&lt;p&gt;I dunno.  As far as it pertains to processing power, memory or storage, I’ve not yet reached a point where for what
we’re doing I need to switch.  But, I may take advantage of the instances for my next Investigation.  I’ve got some
ideas…&lt;/p&gt;

&lt;p&gt;In any case, I had hoped or planned to keep my feet wet in HackerRank by maintaining a slow pace of about a challenge
a day.  The track I was working on was the SQL track.  Given the focus on SQL with Project Three, I decided to ramp it
up a bit and try to finish the track.  This worked well enough… until the last challenge in the “Advanced Join”
category.  That was my final challenge for the whole track.  It was marked “Hard” and had a lower completion score
than the others (meaning fewer people who’d ever attempted it eventually succeeded).  I was determined NOT to look
to the Discussions for help.  I lost several hours on it before abandoning it.&lt;/p&gt;

&lt;p&gt;I didn’t touch HackerRank after that because the work for Project Three and the Challenge Sets had buried me.
HackerRank got lonely and sent me an email suggesting that I work on that very challenge.  Chuckle…&lt;/p&gt;

&lt;p&gt;Well… the SQL Challenge Set from Metis gave me lots of relevant practice.  This Challenge Set was broken into
four sections:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SQL via a tutorial website&lt;/li&gt;
  &lt;li&gt;SQL via a Python SQLAlchemy interface to a Postgres database&lt;/li&gt;
  &lt;li&gt;SQLite&lt;/li&gt;
  &lt;li&gt;SQL with a Postgres database directly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hilariously, I completely missed the requirement of SQLAlchemy for that second part till the last challenge.  I was indeed
using the sqlalchemy module, but only to get a connection with which I was simply pumping in raw SQL.  The last challenge
made a remark about what you’d have to do because SQLAlchemy didn’t support a particular functionality.  This made no sense
to me until it dawned on me what I was supposed to have been doing all along.  Sigh… So I had to back up and redo the
entire section.  This was a huge blessing though.  It very much helped to already have SQL that worked so I could
“translate” to the way SQLAlchmey works.&lt;/p&gt;

&lt;p&gt;Well… Project Three is largely done.  I still have a bit of work to “publish” it.  But as somewhat of a diversion, a bit
of a cooldown, or just to wrap up loose ends, I decided to finish that track on HackerRank.&lt;/p&gt;

&lt;p&gt;I built a small database to replicate the sample shown in the project description and fired up a Jupyter notebook to
hammer away at it.  I finally got it working!!  I thought I’d have to use a bit of recursion, but that proved unnecessary.
I just had to carefully construct enough WITH clauses to get the job done.  Ironically, PostgreSQL is not supported by
HackerRank.  So I chose Oracle and then had to “translate”.&lt;/p&gt;

&lt;p&gt;All done!&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="SQL" /><summary type="html">Yay!! I finally finished the SQL track on HackerRank!</summary></entry><entry><title type="html">Tired… so… tired…</title><link href="/metis/2018/02/22/Tired-So-Tired/" rel="alternate" type="text/html" title="Tired... so... tired..." /><published>2018-02-22T00:00:00+00:00</published><updated>2018-02-22T00:00:00+00:00</updated><id>/metis/2018/02/22/Tired-So-Tired</id><content type="html" xml:base="/metis/2018/02/22/Tired-So-Tired/">&lt;p&gt;I am incredibly tired.&lt;/p&gt;

&lt;p&gt;We have reached another milestone in the Bootcamp.  We have finished Project Three and have begun Project Four.
Everyone else gave their presentation for Project Three yesterday and I wrapped it up by presenting mine
this morning.  There is an interesting segue between projects where folk wrap up their work for submission,
which includes “publishing” their presentation along with pertinent code, etc., and then the brainstorming
for the next project.&lt;/p&gt;

&lt;p&gt;I was out for a planned absence Monday and then I got sick.  It was something similar to stomach flu, food
poisoning or possibly I weak case of the flu (which is possible since I did get the shot a few weeks ago).
The illness had a greater impact due to the fact I needed the rest and quite literally couldn’t maintain
focus.&lt;/p&gt;

&lt;p&gt;I was able to work over the weekend and was the first to submit the last &lt;em&gt;required&lt;/em&gt; Challenge Set.  We’re
still getting a couple challenge sets a week.  But from here on out, they’re all optional.  And, again, the
prioritization is Projects first, Blog second, Challenges next.&lt;/p&gt;

&lt;p&gt;So… what I &lt;strong&gt;should&lt;/strong&gt; be doing right now is Project.  I have to publish my stuff.  So… why am I blogging
instead?  Well… because I’m fried.  I’m not the only one, of course.  Derrick gave his Investigation
presentation early this afternoon and he warned us he was going to be much more mellow then normal because
he’s so tired.  And Dean was yawning as much as I was.&lt;/p&gt;

&lt;p&gt;I cannot speak for everyone else.  Especially since I wasn’t here this week till Wednesday.  But I get a
feeling many others work just as hard on their projects.  I really do wish I had been here to help my
“team”.  The projects are solo now.  But we’re still grouped into clusters where we’re supposed to keep
tabs on each other, help each other, even represent each other.  Amy channelled me as she imitated me during
the MVP and she was much louder as a result.  I was supposed to be here to help her practice.  I’m not
sure it would have mattered.  But she drifted back to being really quiet during her presentation 
yesterday.  She did good otherwise.  As did Michael.  Michael’s project was on predicting likelihood of
Chicago restaurants failing inspections.  He called out the restaurant we went to for Chinese New Year’s,
which was hilarious since my wife, at least, believes that to be a strong contender for my illness.  I
sort of doubt it since that would have meant a much longer time than usual between bad food and the
onset of symptoms.  But who knows.&lt;/p&gt;

&lt;p&gt;I was rather intent on getting back Wednesday to see the other presentations.  I learned quite a bit,
not only from what they presented including all their methods and tools but also from the feedback
the instructors gave them.  I was halfway done with my presentation (having stayed up very, very late
the night before) and probably could have winged an incomplete slide show.  But Alice was rather
gracious in giving me an extra day - like they did for Amy who was actually sick the day of presentations
for Project Two.  I knew I needed the time so I took it.&lt;/p&gt;

&lt;p&gt;And I really did need it.  I &lt;strong&gt;again&lt;/strong&gt; stayed up very, very late.  Some of what I was chasing wasn’t
strictly necessary.  But there were a couple of ideas I wanted to explore and have tried out in case
I got any questions pointing in that direction.  I did NOT get around to a working example of using
plotly.js.  And it didn’t help matters that I had to spend some time addressing laptop and virtual
machine issues because one of the (virtual) hard drives for the VM (the one running Postgres… which
I was dependent on for this project) had to be resized.&lt;/p&gt;

&lt;p&gt;The next project is reportedly a very difficult one for students.  We’re shifting from Supervised
Learning to Unsupervised Learning.  And no… this has nothing to do with us being given more freedom.
Many of us used the experience of Project One to guide our choice of what to do for Project Two.
But things are different enough for Project Three that we may not quite be as able to choose wisely.&lt;/p&gt;

&lt;p&gt;In any case, I’m having a ball and learning a ton.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">I am incredibly tired.</summary></entry></feed>