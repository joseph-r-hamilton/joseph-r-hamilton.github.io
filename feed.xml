<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-01-20T05:02:41+00:00</updated><id>/</id><title type="html">Joseph Hamilton - Solution Oriented Data Scientist</title><subtitle>A website by and for Joseph Hamilton. A place to explore projects and pursuits, to chase curiosities and catch dreams.
</subtitle><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><entry><title type="html">Project Benson MVP</title><link href="/project/benson/2018/01/19/Project-Benson-Closing/" rel="alternate" type="text/html" title="Project Benson MVP" /><published>2018-01-19T00:00:00+00:00</published><updated>2018-01-19T00:00:00+00:00</updated><id>/project/benson/2018/01/19/Project-Benson-Closing</id><content type="html" xml:base="/project/benson/2018/01/19/Project-Benson-Closing/">&lt;p&gt;Project Benson is wrapping up.&lt;/p&gt;

&lt;p&gt;We are supposed to be ready to present Monday morning.  We were supposed to have finished up our presentations.
We were supposed to have had a practice presentation.&lt;/p&gt;

&lt;p&gt;We aren’t quite there.  Oh we’re gonna have to present no matter what.  And there was a scheduled social event
to cap out Week-One which really did break the stress and focus, so to speak.&lt;/p&gt;

&lt;p&gt;But I’m not sure any of our groups are truly at a point where they’re not going to be working on this over the
weekend.  And there is a reason they laid out this goal (of having it wrapped up and being free over the weekend)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;they gave us homework… which… ironically would
have been useful &lt;strong&gt;before&lt;/strong&gt; attacking this project.  I’m sure it’ll help reinforce things.  Indeed, I’m
rather certain that’s part of the entire pedagogy here.  We’re getting this training before, during and after
while under immense pressure.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If all of the above sounds like doom and gloom, you’re reading it wrong.  I’m thrilled with this.  And I sense
a lot of the others are enjoying this too.  It’s just so fast paced.  And when you force yourself to cut to
the next aspect (for example, from data wrangling to visualization), you have to start an uphill climb all
over again.  You may have gained some confidence by gaining some fluidity in the previous aspect only to feel
like an infant all over again.&lt;/p&gt;

&lt;p&gt;So… enough meta data.  What did we &lt;strong&gt;do&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;Last night I fought with the available geographic data to get a location data for each “Station” in the
MTA data.  The NY data provides geo-data but it is not cleanly aligned with the MTA data.  A bit of patient,
manual sorting and matching got me about 90% there.  Google and Wikipedia got me to about 99%.  For the rest
I just had to make some quasi-intelligent decisions.&lt;/p&gt;

&lt;p&gt;I fought through installation of several libraries and played with plots with maps.  I eventually got a
basic heatmap of all the MTA stations.  It didn’t dawn on me until I could &lt;strong&gt;SEE&lt;/strong&gt; it how odd it is to
be incorporating the non-Manhattan burroughs and simply ignoring Jersey entirely.  The problem statement
didn’t specify Manhattan as the location of the gala, although it seems intuitive.  But the problem statement
clearly lays out the scenario as one where the Customer/Client already had the focus on the MTA.  Too late
now to do anything about it.&lt;/p&gt;

&lt;p&gt;But… this is probably a good example of the issue of putting Design before Data.  Jump right into the
MTA data and you’re locked and biased in that view.  Maybe if you just thought whether it made any sense
to analyze the burroughs the concept of Jersey could have arisen.&lt;/p&gt;

&lt;p&gt;We may have ruled it out.   Indeed, we may have chosen to ignore the burroughs if we could.  But what strikes
me is how we utterly ignored New Jersey entirely.&lt;/p&gt;

&lt;p&gt;Otherwise, the challenge for our team today was to shift from Data Analysis to Visualization.  We simply
did not have the time to properly synchronize or synthesize our various methodologies.  All of our were
doing slightly different things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Me: a Time Series resampling, interpolation, cleaning&lt;/li&gt;
  &lt;li&gt;Derrick: a “min-max” per day approach&lt;/li&gt;
  &lt;li&gt;Kendall: a weighted average rather than “dumb” interpolation&lt;/li&gt;
  &lt;li&gt;Dean: working on code that would take clean data from one of the rest and do further analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the most part, as much as we could test it, all of our approaches were showing the same top sites
in a ranking by traffic.  Derrick had a challenge because it was harder to remove the anomalies with
his method and harder still to limit the impact (those anomalies cost me a 4 hour block and I switched
to interpolating the gap; it cost him a day).  Kendall got her more complicated method mostly working
but before we could really contrast and compare we had to move on.&lt;/p&gt;

&lt;p&gt;Since I was ready with clean data a bit earlier, I’d moved from working with the single per-week dumps
from the MTA and using the yearly dumps from NY.  I grepped (yes… literally using grep) the months
of March, April and May from each of 2015, 2016 and 2017, processed these and one-by-one fed the
data to Dean.  Dean and I then struggled with it.  We fought through issues of Pandas so we could 
do analysis and start making charts.  I found almost no variation in the ranking of the first ten
sites when looking at all three months vs. one week in the 2017 data.&lt;/p&gt;

&lt;p&gt;I made some charts and spent a lot of time beating my head against the arcane details of matplotlib.
I pushed some charts to our group repository and Kendall provided me some feedback to change a few
things to align more with the morning’s lecture on Visualization.&lt;/p&gt;

&lt;p&gt;Eventually Dean drafted a Presentation and we sort of discussed who’d say what.  We will be wrapping
up charts, etc. and will present.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Benson is wrapping up.</summary></entry><entry><title type="html">Bootcamp - First Week Wrapup</title><link href="/metis/2018/01/19/Bootcamp-First-Week-Wrapup/" rel="alternate" type="text/html" title="Bootcamp - First Week Wrapup" /><published>2018-01-19T00:00:00+00:00</published><updated>2018-01-19T00:00:00+00:00</updated><id>/metis/2018/01/19/Bootcamp-First-Week-Wrapup</id><content type="html" xml:base="/metis/2018/01/19/Bootcamp-First-Week-Wrapup/">&lt;p&gt;We have concluded the First Week!  Yay!&lt;/p&gt;

&lt;p&gt;The pace has been brutal.  Many of us are extremely sleep deprived.&lt;/p&gt;

&lt;p&gt;I was up very late last night forcing myself to incorporate the geo-data.
I then fought through library installation (and a bit of library debugging) to be able to follow some
examples I’ve seen on the web.  I got a basic heat map going.  It’s almost meaningless for our purposes.
But it’s good for street cred - it impressed some of my peers.  Several were only barely behind me.  Shortly
after I got there this morning Tiffany asked me about her troubles installing basemap.  I “slacked” her the
command lines I used to install that and half-a-dozen other modules.&lt;/p&gt;

&lt;p&gt;Oh yeah… on that… they weren’t kidding we DO use Slack a ton.  But we use it for &lt;strong&gt;work&lt;/strong&gt; even more
than for the lessons or other messaging.  It doesn’t replace email.  It’s just a &lt;strong&gt;very&lt;/strong&gt; convenient
way to do a quick-and-dirty cut-and-paste of a URL, a code snippet, a file, etc.  For a lot of things, there’s
no point to say “look at this”.  Why waste the other person’s time making them get up and walk around the
table.  They’re busy; you’re busy.  You use half-your brain to cut-and-paste to answer a peer’s question
while they’re wrestling with their problem and you’re struggling with yours.&lt;/p&gt;

&lt;p&gt;At 5pm, we segued into a Social for a couple of hours.  Light snacks, booze and some goofy games.
This stuff is important too.  Many of us are competitive.  Many of us are presumptuous, even precocious.
We’re often criticizing each other’s work and even arguing over methodology.  It is very helpful to
simply chill out and even be silly.&lt;/p&gt;

&lt;p&gt;The first Week concluding aligns more or less with the first Project concluding.  I had to chuckle when
I came across some of the curriculum/guideline that explained when the first project would truly be over.
It’s over when you blog about it.  Chuckle… OK.  It would be silly to claim the fact I had that project
set up on my blog within hours of the beginning of the project means I’ve already met that requirement.
But I’ve &lt;strong&gt;been&lt;/strong&gt; blogging about the project.&lt;/p&gt;

&lt;p&gt;However, we had our lesson on blogging today.&lt;/p&gt;

&lt;p&gt;And I’m horrified.&lt;/p&gt;

&lt;p&gt;Let me explain… if I thought earlier that having gotten the blog out of the way ahead of time would mean
I would have more “free time”, this was slightly incorrect.  Why?  Well… because there wasn’t that much
time in the day where I could have just ignored the lecture.  But that’s not what terrifies me.  No…
what scares me is reflecting that the contrast between the other students getting a short lecture on
blogs despite time required to get a good one going is the same sort of thing I’m going to face shortly
on other aspect such as Stats.  Coupled with the rapid pace on other topics, it’s clear I may have been
right to believe things would get tough after the first couple of weeks.&lt;/p&gt;

&lt;p&gt;Oh well… time to gird my loins.&lt;/p&gt;

&lt;p&gt;And doggone it if I didn’t actually catch a blog bug today anyway.  During the lecture on Visualization, the
declaration of what or Presentation should be made me think.  We are expected to create a slide presentation.
Well… I thought this is exactly what would look good on the blog.  Yeah, sure it would be sufficient
all on its own.  But it would be sweet if I could add that functionality…&lt;/p&gt;

&lt;p&gt;Yup.  So sure enough, I’ll be working on my blog anyway!  Just like everyone else.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">We have concluded the First Week! Yay!</summary></entry><entry><title type="html">More Blog Enhancements</title><link href="/blog/2018/01/19/Blog-More-Enhancements/" rel="alternate" type="text/html" title="More Blog Enhancements" /><published>2018-01-19T00:00:00+00:00</published><updated>2018-01-19T00:00:00+00:00</updated><id>/blog/2018/01/19/Blog-More-Enhancements</id><content type="html" xml:base="/blog/2018/01/19/Blog-More-Enhancements/">&lt;p&gt;I’ve caught a desire to add some functionality to the blog…&lt;/p&gt;

&lt;p&gt;I felt something was… well… missing with the layout for projects that I’ve seen during my
exploratory forays into how folk out in the wild web are using Jekyll sites for these sorts of
things.  The HydeJack Pro theme is in line with most.  And with the addition of a link back
to blog posts about the project, I’m fairly comfortable with it… but…&lt;/p&gt;

&lt;p&gt;Today, I was inspired when we reviewed the expected format for a slide presentation for the
first project of the Metis bootcamp.  I imagined that would help a ton.  I may be going a bit
too far with regards to what others (as in recruiters, employeers, etc.) may want to see vs.
what I want to see.  But I just feel a dense batch of text may not be the best way to present
a project.  I mean, what would separate that from the blogging itself?  Furthermore a quick
hope from the austere front page I’ve set up to a similarly sparse presentation may be nice.
Folk can do a quick get-in/get-out.  If they want, they’ll be more robust stuff to pursue.&lt;/p&gt;

&lt;p&gt;So after a bit of web research, I am going to try to add in some reveal.js magic to the blog.
As before, I’ll likely start with SwirlyPy… my guinea pig project for the purpose of 
having a project on the
blog.  I do intend to get back to that project… eventually… I still feel there’s a place
for that.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><category term="Projects" /><summary type="html">I’ve caught a desire to add some functionality to the blog…</summary></entry><entry><title type="html">Project Benson - Data Exploration 02</title><link href="/project/benson/2018/01/18/Project-Benson-X02/" rel="alternate" type="text/html" title="Project Benson - Data Exploration 02" /><published>2018-01-18T00:00:00+00:00</published><updated>2018-01-18T00:00:00+00:00</updated><id>/project/benson/2018/01/18/Project-Benson-X02</id><content type="html" xml:base="/project/benson/2018/01/18/Project-Benson-X02/">&lt;p&gt;Project Benson - More Data Exploration&lt;/p&gt;

&lt;p&gt;More notebooks I developed as I played around with the data…&lt;/p&gt;

&lt;h3 id=&quot;frustration&quot;&gt;Frustration&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/joseph-r-hamilton/Project_Benson/blob/master/Exploration/Project%20Benson%20-%20Exploration%2002.ipynb&quot;&gt;Project Benson - Exploration 02&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I started to work on an approach using Resampling and Interpolation.  I wanted this done with a MultiIndex.
It seemed tricky but I got it working easily enough…  Except that it returned negative numbers.
For the next day, I backed off and worked in an entirely different manner.  When I finally got that working
and &lt;strong&gt;still&lt;/strong&gt; had negative results, I finally went back and explored the source data only to discover that
some of the turnstile are counting backwards.  The negative results were fine.&lt;/p&gt;

&lt;p&gt;I’ve abandoned this alternative approach.  But it was a good exercise nonetheless.&lt;/p&gt;

&lt;h3 id=&quot;cleanup-analysis&quot;&gt;Cleanup Analysis&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/joseph-r-hamilton/Project_Benson/blob/master/Exploration/Project%20Benson%20-%20Exploration%2003b.ipynb&quot;&gt;Project Benson - Exploration 03b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After returning to the straightforward method, the next step was to try to determine how to clean things up.
Part of this analysis highlighted a need to tweak my methodology.&lt;/p&gt;

&lt;p&gt;Next, however, I had to determine how to handle truly anomalous information.&lt;/p&gt;

&lt;h3 id=&quot;a-clean-notebook&quot;&gt;A Clean Notebook&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/joseph-r-hamilton/Project_Benson/blob/master/Exploration/Project%20Benson%20-%20Exploration%2005.ipynb&quot;&gt;Project Benson - Exploration 05&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After working out methods for Data Cleanup and Aggregation, I created this notebook to serve as a clean way
to show the process, to share with the team and to present to the larger audience.&lt;/p&gt;

&lt;p&gt;This can then serve as a springboard for further analysis and processing.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Benson - More Data Exploration</summary></entry><entry><title type="html">Project Benson MVP</title><link href="/project/benson/2018/01/18/Project-Benson-MVP/" rel="alternate" type="text/html" title="Project Benson MVP" /><published>2018-01-18T00:00:00+00:00</published><updated>2018-01-18T00:00:00+00:00</updated><id>/project/benson/2018/01/18/Project-Benson-MVP</id><content type="html" xml:base="/project/benson/2018/01/18/Project-Benson-MVP/">&lt;p&gt;Project Benson is past MVP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MVP = Minimal Viable Product&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We presented our MVP early this afternoon.  For us, this meant presenting a Jupyter Notebook
that highlighted our methodology crunching the data for one week and turning that into a ranked
order of stations by traffic.&lt;/p&gt;

&lt;p&gt;There are three teams in the entire cohort.&lt;/p&gt;

&lt;p&gt;This isn’t a competition so much but all the teams are essentially tackling the same problem.
Since the entire cohort is the audience for the presentations, it is &lt;em&gt;very&lt;/em&gt; interesting because
we may all be at different points of the discovery or be using different strategies entirely.&lt;/p&gt;

&lt;p&gt;Each team’s presentations had different strengths, etc.&lt;/p&gt;

&lt;p&gt;Our team was the only one that had incorporated the technique of resampling for time series.&lt;/p&gt;

&lt;p&gt;Another team was the only one who had punched through Tableau for some pretty pictures.&lt;/p&gt;

&lt;p&gt;The third team was the only one which had decided to incorporate the geographical data of tech
companies in the greater New York area.&lt;/p&gt;

&lt;p&gt;There’s precious little time left.  We have to have practiced the presentation by end-of-day tomorrow.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Benson is past MVP.</summary></entry><entry><title type="html">Bootcamp - Pair Programming</title><link href="/metis/2018/01/18/Bootcamp-Pair-Programming/" rel="alternate" type="text/html" title="Bootcamp - Pair Programming" /><published>2018-01-18T00:00:00+00:00</published><updated>2018-01-18T00:00:00+00:00</updated><id>/metis/2018/01/18/Bootcamp-Pair-Programming</id><content type="html" xml:base="/metis/2018/01/18/Bootcamp-Pair-Programming/">&lt;p&gt;Pair Programming is… umm… interesting.&lt;/p&gt;

&lt;p&gt;The structure of the Metis Data is broken down such that we cover different things simultaneously,
concurrently rather than just a deep focus on one thing.&lt;/p&gt;

&lt;p&gt;The projects are the emphasis.  So, it is really easy to fall into a mode (or mood) where you’re
absorbed by or focused on the project of the moment.  The lectures and “other things” serve to
break that.&lt;/p&gt;

&lt;p&gt;One of these “things” is &lt;strong&gt;&lt;em&gt;Pair Programming&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Every day starts with about half-an-hour of Pair Programming.&lt;/p&gt;

&lt;p&gt;Pair Programming serves many purposes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The instructors get a chance to see the students’ code on a regular, daily basis.  It’s one thing
to tell the students about certain practices of coding Python.  It’s another thing to confirm or
chastise students to verify they are incorporating these practices.&lt;/li&gt;
  &lt;li&gt;Working in pairs forces people to work together.  Only person gets the computer.  But either may
have the idea.  Nonetheless, you have to communicate and the other can critique accordingly.&lt;/li&gt;
  &lt;li&gt;These are timed exercises.  So the pressure is on.  This then simulates the experience of code
interviews where in a job interview you have to code or whiteboard.  The types of problems are
also similar to the kind you’d experience in code interviews.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Pair Programming is… umm… interesting.</summary></entry><entry><title type="html">Project Benson Progresses</title><link href="/project/benson/2018/01/17/Project-Benson-Progresses/" rel="alternate" type="text/html" title="Project Benson Progresses" /><published>2018-01-17T00:00:00+00:00</published><updated>2018-01-17T00:00:00+00:00</updated><id>/project/benson/2018/01/17/Project-Benson-Progresses</id><content type="html" xml:base="/project/benson/2018/01/17/Project-Benson-Progresses/">&lt;p&gt;Project Benson is underway.&lt;/p&gt;

&lt;p&gt;OK.  The last 24 hours have been somewhat of a rollercoaster with regards to Project Benson.&lt;/p&gt;

&lt;p&gt;I spent a fair amount of time pursuing the data from a Exploratory Data Analysis point of view.
And I simply loved it.  It was good practice with Pandas.  I learned several new aspects of how
to use Pandas for time series sorts of data.  It was also frustrating when I got stuck trying
to do things that appeared to work but didn’t.&lt;/p&gt;

&lt;p&gt;But in the morning Alice reminded us that good Data Scientists do &lt;strong&gt;NOT&lt;/strong&gt; jump right into the data
searching for things that can be done with the data.  A Data Science project begins with Design.
This was a repeat.  I’m pretty sure she said the same thing yesterday.  But… it was bewildering
then and it was chastening today.  Because… the data is so much FUN.&lt;/p&gt;

&lt;p&gt;There’s a number of traps and pitfalls here.  First of all, we may end up either limited by focusing
too much on the data at hand or simply incredibly biased because of this focus.  Next, we can spend
a lot of time pleasing ourselves or attempting to build monuments which may be overkill or mismatched
compared to what anyone ever really wanted.&lt;/p&gt;

&lt;p&gt;So… how do you do Design before jumping into the Data?  We discussed this…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First, &lt;strong&gt;listen&lt;/strong&gt; to your Customers.  Learn what problems they want solved.  Discern what may be
a threshold of satisfaction or a point of diminishing returns.&lt;/li&gt;
  &lt;li&gt;Second, &lt;strong&gt;brainstorm&lt;/strong&gt;.  Think about the problem.  Ponder how you’ll approach the challenge.  Draft your goals.&lt;/li&gt;
  &lt;li&gt;Determine a &lt;strong&gt;MVP - Minimum Viable Product&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This approach should help to guide the overall effort.  It also sets you up for an iterative method
where you can have &lt;em&gt;something&lt;/em&gt; to show for your work ASAP but then build upon it.&lt;/p&gt;

&lt;p&gt;So… what did we do?  Jump back into the data.&lt;/p&gt;

&lt;p&gt;Well.. that’s not entirely true.  We spent a lot of time debating methodology… about the data.&lt;/p&gt;

&lt;p&gt;Nah… we hastily determined our MVP would be simply a ranked list of the MTA stations based on traffic flow.&lt;/p&gt;

&lt;p&gt;But the trouble here is determining how to assess this.  The “fun” part of the MTA data is this isn’t actually
quite readily availble.  You must massage the data a bit.&lt;/p&gt;

&lt;p&gt;Kendall and I discovered each of us had wrestled with trying to determine the structure behind the data.
We still cannot quite figure out what some of it actually means.  Oh we could figure out what to count.
But… there were hints that you might be able to say more if you undertood more of what it represented.&lt;/p&gt;

&lt;p&gt;At some point I described what I’d been doing with standardizing and interpolating by resampling the data.
Kendall and I debated that a lot because her Math/Stats background made her leery of interpolation, especially
dumb linear interpolation.  Dean jumped in and we explored this a bit.  But it wasn’t clear any other thing
we were discussing would be any easier or better.  Derrick stayed quiet and simply plugged away at another
approach altogether.  When he shared his idea, we pointed out the errors inherent in that approach and guided
him how to continue with it by aggregating up to the STATION level.&lt;/p&gt;

&lt;p&gt;All of our approaches have errors.  Linear interpolation makes assumptions about the rate between the
interpolation.  But so do alternative approaches based on other distributions.  Derrick’s approach bumped
up the granurality to 1 day but with known errors around midnight.&lt;/p&gt;

&lt;p&gt;We’re continuing to work on anything and everything.  But we selected Derrick’s approach because it’s
easier to do quicker.  And… boy is this projecting being rushed!  Dean typed up our Design Statement
and submitted it.  Our MVP is due tomorrow, less than 48 hours after the project started!&lt;/p&gt;

&lt;p&gt;Furthermore, if I get the interpolation working it would permit us to the same 4-hour granularity, or
lower as long as we remember it’s interpolated.  And it would very likley corroborate the per-day
approach.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Benson is underway.</summary></entry><entry><title type="html">Saved by Snapshots</title><link href="/metis/2018/01/16/Saved-By-Snapshots/" rel="alternate" type="text/html" title="Saved by Snapshots" /><published>2018-01-16T00:00:00+00:00</published><updated>2018-01-16T00:00:00+00:00</updated><id>/metis/2018/01/16/Saved-By-Snapshots</id><content type="html" xml:base="/metis/2018/01/16/Saved-By-Snapshots/">&lt;p&gt;Guess what… I’ve &lt;strong&gt;already&lt;/strong&gt; benifitted from setting up a snapshot regimen.&lt;/p&gt;

&lt;p&gt;Yup.  That didn’t take long.  I made a global subsitute in a file where I should have specified
only the lines after the cursor.  I didn’t realize what I’d done.  But I was making blogging changes
with Jekyll in update mode.  So I could &lt;strong&gt;see&lt;/strong&gt; I’d screwed something up immediately but I couldn’t
tell what.  And attempting to undo it didn’t work.&lt;/p&gt;

&lt;p&gt;A quick peek into the snapshots directory and it became clear I’d screwed up the YAML header stuff.
Again… YAML is &lt;strong&gt;PICKY&lt;/strong&gt;!!&lt;/p&gt;

&lt;p&gt;I loved having this many years ago on Solaris.  So I knew of the benefit of having it.  And I imagined
I’d need it to protet myself from myself.  I didn’t expect to need it so soon.  :grin:&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Guess what… I’ve already benifitted from setting up a snapshot regimen.</summary></entry><entry><title type="html">Project Benson - Data Exploration 01</title><link href="/project/benson/2018/01/16/Project-Benson-X01/" rel="alternate" type="text/html" title="Project Benson - Data Exploration 01" /><published>2018-01-16T00:00:00+00:00</published><updated>2018-01-16T00:00:00+00:00</updated><id>/project/benson/2018/01/16/Project-Benson-X01</id><content type="html" xml:base="/project/benson/2018/01/16/Project-Benson-X01/">&lt;p&gt;Project Benson - Data Exploration&lt;/p&gt;

&lt;p&gt;Follow the link below to a Jupyter Notebook encapsulating my initial Data Exploration related to Project Benson.&lt;/p&gt;

&lt;p&gt;This includes some investigation, some chaos, some play, some fun, etc.  Working towards what techniques
may work for our overall project.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/joseph-r-hamilton/Project_Benson/blob/master/Exploration/Project%20Benson%20-%20Exploration%2001.ipynb&quot;&gt;Project Benson - Exploration 01&lt;/a&gt;&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Benson - Data Exploration</summary></entry><entry><title type="html">Project Benson Begins</title><link href="/project/benson/2018/01/16/Project-Benson-Begins/" rel="alternate" type="text/html" title="Project Benson Begins" /><published>2018-01-16T00:00:00+00:00</published><updated>2018-01-16T00:00:00+00:00</updated><id>/project/benson/2018/01/16/Project-Benson-Begins</id><content type="html" xml:base="/project/benson/2018/01/16/Project-Benson-Begins/">&lt;p&gt;Project Benson has begun.&lt;/p&gt;

&lt;p&gt;Wow.  We hit the ground running alright.&lt;/p&gt;

&lt;p&gt;First day of the bootcamp and we’re busy on the first project.&lt;/p&gt;

&lt;p&gt;The projets throughout the Metis Bootcamp seem to trend in a couple of ways.  One trend is from a group
effort to a solo effort.  For this first project, my partners in crime are Dean, Derrick and Kendall.
We sequestered ourselves at the sunny side of the floorspace and barricaded ourselves from the rest of
the world as we discussed how best to attack the problem.&lt;/p&gt;

&lt;p&gt;Kendall and I were the first to find the data.  But we found it in different places.  And it’s good that
we did so.  The &lt;a href=&quot;http://web.mta.info/developers/download.html&quot;&gt;MTA site&lt;/a&gt; provides the data in smaller
chunks, which should prove more amenable to rapid prototyping.  But as Kendall dug into the data available
on the &lt;a href=&quot;https://data.ny.gov/&quot;&gt;New York site&lt;/a&gt; site, we realized it was the same data, same columns, but…
the data was available in entirety, millions of rows of it.&lt;/p&gt;

&lt;p&gt;We chatted about what to look for… or how to use the data available.  Did we care about location down
the level of which street exit of any particular station?  Should we focus on Spring traffic since the
problem statement suggested an event at the start of Summer?  Dare we try to accommodate or consider
the effect of Spring Break?&lt;/p&gt;

&lt;p&gt;We looked at the data enough to realize we had some data munging to do so we clearly needed something
in the fashion of people per unit time at any station while the turnstile data is just reporting a
(supposedly) ever increasing count of the actual turnstile reader.&lt;/p&gt;

&lt;p&gt;We broke with the idea that we should first play with the data more and then we could scale or filter
as we chose.  Furthermore, Dean stated he would attempt to work in Tableau since he had access to that.
This is one of those benefits to the group aspect of the Metis Bootcamp.  We all bring different things
to the table and can share and learn from one another.&lt;/p&gt;</content><author><name>Joseph Hamilton</name><email>hamilton.joseph.r@gmail.com</email></author><summary type="html">Project Benson has begun.</summary></entry></feed>