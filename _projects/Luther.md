---
layout:       project
date:         24 Jan 2018
title:        Luther
caption:      An exercise in web scraping and linear regression
description:  >
  A journey through web scraping to accumulate data for linear regression.
image:        /assets/img/projects/Luther/Luther.jpg
screenshot:
  src:        /assets/img/projects/Luther/Luther.jpg
  srcset:
    1920w:    /assets/img/projects/Luther/Luther.jpg
    960w:     /assets/img/projects/Luther/Luther@0,5x.jpg
    480w:     /assets/img/projects/Luther/Luther@0,25x.jpg
links:
  - title:    Related Posts
    url:      /category/luther
featured:     true
accent_color: '#4fb1ba'
accent_image: /assets/img/projects/Luther/Luther_sidebar-bg.jpg
---

# Project Luther - Web Scraping and Linear Regression
## Exploring the impact of various features related to property tax and valuation on neighborhood stability.

## Back Story

An email soliciting assistance in exploration and investigation:

>
Joseph
>
Greetings.  I was very intrigued in our recent discussion about Data
Science.  It was interesting to learn about how folk use computing
to analyze data to draw insights.
>
Well, the group I work with would like your assistance to chase a
curiosity.  Is there a way to discern from publicly available housing
data what factors influcence neighborhood stability in the sense that
people stay in their houses for longer periods of time?
>
thanks in advance,
>
Frank Russell Trated

## Initial response...

>
Frank,
>
I'm including here the presentation we reviewed which described my
initial assessment of the possiblity of using publically available
data provided by the local governments for Property Tax purposes.
>
I will continue to explore this topic and provide a final report
after further investigation and analysis.
>
regards,
>
Joseph

[Project Luther MVP](/slides/luther_mvp/){:target="_blank"} 
  
## Final response...
>
Frank,
>
It was a pleasure to be able to explore this topic.
>
However, as suggested during the MVP review, the data doesn't
seem to suggest we create models via linear regression here
with significant predictive power.
>
I was indeed able to scrape far more data.  But an analysis of the
modeling demonstrated the problem here isn't with the amount of
data.  More data isn't going to (and didn't) create a signal to
capture where one may not exist.
>
I am providing links below to the final presentation and related
items.
>
regards,
>
Joseph Hamilton

* [Web Scraping code (Scrapy)](https://github.com/joseph-r-hamilton/Regression_Study_Longevity/tree/master/Exploration/lutherbot)
* [Analysis (Jupyter Notebook)](/assets/html/Project Luther Analysis.html)
* [Final Presentation](/slides/luther/){:target="_blank"} 

